{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b2a518-cb2f-436c-8488-987a16a04a40",
   "metadata": {},
   "source": [
    "# Algorithm explainer / figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e27e7691-8d7a-4d02-93e8-11a0c98375ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from IPython.display import Image, display\n",
    "from cmcrameri import cm as cmc\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.signal import find_peaks\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.gridspec as gsp\n",
    "import icelakes\n",
    "from icelakes.utilities import encedc, decedc\n",
    "from icelakes.nsidc import download_granule, edc\n",
    "from icelakes.detection import read_atl03, detect_lakes, melt_lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d22be-95ef-460f-bd29-df92f07cf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'ATL03_20190716051841_02770403_005_01.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3105a1-5783-4577-8579-ac05a983fa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd3b95a-db34-4c39-8427-ac17eb639cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# photon_data, bckgrd_data, ancillary = read_atl03(input_filename, geoid_h=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944ec7ae-fe84-44ba-8745-5d0d567087d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictobj:\n",
    "    def __init__(self, in_dict:dict):\n",
    "        assert isinstance(in_dict, dict)\n",
    "        for key, val in in_dict.items():\n",
    "            setattr(self, key, val)\n",
    "                \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    def plot_detected(self, fig_dir='figs', verbose=False, min_width=0.0, min_depth=0.0, print_mframe_info=True):\n",
    "\n",
    "        import matplotlib\n",
    "        from matplotlib.patches import Rectangle\n",
    "\n",
    "        if len(self.detection_2nd_returns['h'])>0:\n",
    "            lake_minh = np.min(self.detection_2nd_returns['h'])\n",
    "        else: return\n",
    "        lake_max_depth = np.abs(self.main_peak - np.min(self.detection_2nd_returns['h']))\n",
    "        lake_segment_length = np.abs(np.max(self.detection_2nd_returns['xatc']) - np.min(self.detection_2nd_returns['xatc']))\n",
    "        lake_maxh = np.min((self.mframe_data['peak'].max(), self.main_peak+0.5*lake_max_depth))\n",
    "        buffer_bottom = np.max((0.5*lake_max_depth, 2.0))\n",
    "        lake_minh_plot = lake_minh - buffer_bottom\n",
    "        buffer_top = (lake_maxh - lake_minh_plot) * 0.5\n",
    "        lake_maxh_plot = lake_maxh + buffer_top\n",
    "        ylms = (lake_minh_plot, lake_maxh_plot)\n",
    "        xlms = (0.0, self.mframe_data.xatc_max.max())\n",
    "\n",
    "        if (lake_max_depth > min_depth) & (lake_segment_length > min_width):\n",
    "            fig, ax = plt.subplots(figsize=[9, 5], dpi=100)\n",
    "\n",
    "            # plot the ATL03 photon data\n",
    "            scatt = ax.scatter(self.photon_data.xatc, self.photon_data.h,s=5, c=self.photon_data.snr, alpha=1, \n",
    "                               edgecolors='none', cmap=cmc.lajolla, vmin=0, vmax=1)\n",
    "            p_scatt = ax.scatter([-9999]*4, [-9999]*4, s=15, c=[0.0,0.25,0.75,1.0], alpha=1, edgecolors='none', cmap=cmc.lajolla, \n",
    "                                 vmin=0, vmax=1, label='ATL03 photons')\n",
    "\n",
    "            # plot surface elevation\n",
    "            for xtent in self.surface_extent_detection:\n",
    "                ax.plot(xtent, [self.surface_elevation, self.surface_elevation], 'g-', lw=3)\n",
    "            p_surf_elev, = ax.plot([-9999]*2, [-9999]*2, 'g-', lw=3, label='lake surface')\n",
    "\n",
    "            # plot the second returns from detection\n",
    "            for j, prom in enumerate(self.detection_2nd_returns['prom']):\n",
    "                ax.plot(self.detection_2nd_returns['xatc'][j], self.detection_2nd_returns['h'][j], \n",
    "                                        marker='o', mfc='none', mec='b', linestyle = 'None', ms=prom*8)\n",
    "            p_2nd_return, = ax.plot(-9999, -9999, marker='o', mfc='none', mec='b', ls='None', ms=3, label='second returns')\n",
    "\n",
    "            # plot mframe bounds\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "            mframe_bounds_xatc = list(self.mframe_data['xatc_min']) + [self.mframe_data['xatc_max'].iloc[-1]]\n",
    "            for xmframe in mframe_bounds_xatc:\n",
    "                ax.plot([xmframe, xmframe], [ymin, ymax], 'k-', lw=0.5)\n",
    "\n",
    "            # visualize which segments initially passed\n",
    "            for i, passing in enumerate(self.mframe_data['lake_qual_pass']):\n",
    "                mf = self.mframe_data.iloc[i]\n",
    "                if passing:\n",
    "                    xy = (mf.xatc_min, ylms[0])\n",
    "                    width = mf.xatc_max - mf.xatc_min\n",
    "                    height = ylms[1] - ylms[0]\n",
    "                    rct = Rectangle(xy, width, height, ec=(1,1,1,0), fc=(0,0,1,0.1), zorder=-1000, label='major frame passed lake check')\n",
    "                    p_passed = ax.add_patch(rct)\n",
    "                p_mfpeak, = ax.plot((mf.xatc_min,mf.xatc_max), (mf.peak,mf.peak),'k-',lw=0.5, label='major frame peak')\n",
    "\n",
    "            # add a legend\n",
    "            hdls = [p_scatt, p_surf_elev, p_2nd_return, p_mfpeak, p_passed]\n",
    "            ax.legend(handles=hdls, loc='lower left', fontsize=7, scatterpoints=4)\n",
    "\n",
    "            # add the colorbar \n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes('right', size='4%', pad=0.05)\n",
    "            cbar = fig.colorbar(scatt, cax=cax, orientation='vertical')\n",
    "            cbar.ax.get_yaxis().set_ticks([])\n",
    "            for j, lab in enumerate([0.2, 0.4, 0.6, 0.8]):\n",
    "                cbar.ax.text(.5, lab, '%.1f'%lab, ha='center', va='center', fontweight='black')\n",
    "            cbar.ax.get_yaxis().labelpad = 15\n",
    "            cbar.ax.set_ylabel('photon density', rotation=270, fontsize=8)\n",
    "\n",
    "            # add labels and description in title\n",
    "            txt  = 'ICESat-2 Lake Detection: %s, ' % ('Greenland Ice Sheet' if self.lat>=0 else 'Antarctic Ice Sheet')\n",
    "            txt += '%s Melt Season' % self.melt_season\n",
    "            fig.suptitle(txt, y=0.95, fontsize=14)\n",
    "\n",
    "            txt  = 'location: %s, %s (area: %s) | ' % (self.lat_str, self.lon_str, self.polygon_name)\n",
    "            txt += 'time: %s UTC | surface elevation: %.2f m\\n' % (self.date_time, self.surface_elevation)\n",
    "            txt += 'RGT %s %s cycle %i | ' % (self.rgt, self.gtx.upper(), self.cycle_number)\n",
    "            txt += 'beam %i (%s, %s spacecraft orientation) | ' % (self.beam_number, self.beam_strength, self.sc_orient)\n",
    "            txt += 'granule ID: %s' % self.granule_id\n",
    "            ax.set_title(txt, fontsize=8)\n",
    "\n",
    "            ax.set_ylabel('elevation above geoid [m]',fontsize=8)\n",
    "            ax.tick_params(axis='x', which='major', labelsize=7)\n",
    "            ax.tick_params(axis='y', which='major', labelsize=6)\n",
    "            # set limits\n",
    "            ax.set_ylim(ylms)\n",
    "            ax.set_xlim(xlms)\n",
    "\n",
    "            # add latitude\n",
    "            #_________________________________________________________\n",
    "            lx = self.photon_data.sort_values(by='lat').iloc[[0,-1]][['lat','xatc']].reset_index(drop=True)\n",
    "            lat = np.array(lx.lat)\n",
    "            xatc = np.array(lx.xatc)\n",
    "            def forward(x):\n",
    "                return lat[0] + x * (lat[1] - lat[0]) / (xatc[1] - xatc[0])\n",
    "            def inverse(l):\n",
    "                return xatc[0] + l * (xatc[1] - xatc[0]) / (lat[1] - lat[0])\n",
    "            secax = ax.secondary_xaxis(-0.065, functions=(forward, inverse))\n",
    "            secax.xaxis.set_minor_locator(matplotlib.ticker.AutoMinorLocator())\n",
    "            secax.set_xlabel('latitude / along-track distance',fontsize=8,labelpad=0)\n",
    "            secax.tick_params(axis='both', which='major', labelsize=7)\n",
    "            secax.ticklabel_format(useOffset=False) # show actual readable latitude values\n",
    "\n",
    "            # rename x ticks\n",
    "            xticklabs = ['%g km' % (xt/1000) for xt in list(ax.get_xticks())]\n",
    "            ticks = ax.get_xticks()\n",
    "            ax.set_xticks(ticks)\n",
    "            ax.set_xticklabels(xticklabs)\n",
    "\n",
    "            # add mframe info text\n",
    "            if print_mframe_info:\n",
    "                txt  = 'mframe:\\n' % (mf.name%1000)\n",
    "                txt += 'photons:\\n' % mf.n_phot\n",
    "                txt += 'peak:\\n'\n",
    "                txt += 'flat:\\n'\n",
    "                txt += 'SNR surf:\\n'\n",
    "                txt += 'SNR up:\\n'\n",
    "                txt += 'SNR low:\\n'\n",
    "                txt += '2nds:\\n'\n",
    "                txt += '2nds strength:\\n'\n",
    "                txt += '2nds number:\\n'\n",
    "                txt += '2nds spread:\\n'\n",
    "                txt += '2nds align:\\n'\n",
    "                txt += '2nds quality:\\n'\n",
    "                txt += 'pass:'\n",
    "                trans = ax.get_xaxis_transform()\n",
    "                bbox = {'fc':(1,1,1,0.75), 'ec':(1,1,1,0), 'pad':1}\n",
    "                ax.text(-0.05, 0.98, txt, transform=trans, fontsize=4, ha='right', va='top', bbox=bbox)\n",
    "                for i,loc in enumerate(self.mframe_data['xatc']):\n",
    "                    mf = self.mframe_data.iloc[i]\n",
    "                    txt  = '%i\\n' % (mf.name%1000)\n",
    "                    txt += '%i\\n' % mf.n_phot\n",
    "                    txt += '%.2f\\n' % mf.peak\n",
    "                    txt += '%s\\n' % ('Yes.' if mf.is_flat else 'No.')\n",
    "                    txt += '%i\\n' % np.round(mf.snr_surf)\n",
    "                    txt += '%i\\n' % np.round(mf.snr_upper)\n",
    "                    txt += '%i\\n' % np.round(mf.snr_lower)\n",
    "                    txt += '%i%%\\n' % np.round(mf.ratio_2nd_returns*100)\n",
    "                    txt += '%.2f\\n' % mf.quality_secondreturns\n",
    "                    txt += '%.2f\\n' % mf.length_penalty\n",
    "                    txt += '%.2f\\n' % mf.range_penalty\n",
    "                    txt += '%.2f\\n' % mf.alignment_penalty\n",
    "                    txt += '%.2f\\n' % mf.quality_summary\n",
    "                    txt += '%s' % ('Yes.' if mf.lake_qual_pass else 'No.')\n",
    "                    trans = ax.get_xaxis_transform()\n",
    "                    bbox = {'fc':(1,1,1,0.75), 'ec':(1,1,1,0), 'pad':1}\n",
    "                    ax.text(loc, 0.98, txt, transform=trans, fontsize=4,ha='center', va='top', bbox=bbox)\n",
    "#                 for i,loc in enumerate(self.mframe_data['xatc_min']):\n",
    "#                     mf = self.mframe_data.iloc[i]\n",
    "#                     txt  = 'mframe: %i\\n' % (mf.name%1000)\n",
    "#                     txt += 'photons: %i\\n' % mf.n_phot\n",
    "#                     txt += 'peak: %.2f\\n' % mf.peak\n",
    "#                     txt += 'flat: %s\\n' % ('Yes.' if mf.is_flat else 'No.')\n",
    "#                     txt += 'SNR surf: %i\\n' % np.round(mf.snr_surf)\n",
    "#                     txt += 'SNR up: %i\\n' % np.round(mf.snr_upper)\n",
    "#                     txt += 'SNR low: %i\\n' % np.round(mf.snr_lower)\n",
    "#                     txt += '2nds: %i%%\\n' % np.round(mf.ratio_2nd_returns*100)\n",
    "#                     txt += '2nds strength: %.2f\\n' % mf.quality_secondreturns\n",
    "#                     txt += '2nds number: %.2f\\n' % mf.length_penalty\n",
    "#                     txt += '2nds spread: %.2f\\n' % mf.range_penalty\n",
    "#                     txt += '2nds align: %.2f\\n' % mf.alignment_penalty\n",
    "#                     txt += '2nds quality: %.2f\\n' % mf.quality_summary\n",
    "#                     txt += 'pass: %s' % ('Yes.' if mf.lake_qual_pass else 'No.')\n",
    "#                     trans = ax.get_xaxis_transform()\n",
    "#                     bbox = {'fc':(1,1,1,0.75), 'ec':(1,1,1,0), 'pad':1}\n",
    "#                     ax.text(loc+5, 0.99, txt, transform=trans, fontsize=4, va='top', bbox=bbox)\n",
    "\n",
    "            # add detection quality description\n",
    "            txt  = 'LAKE QUALITY: %6.4f'%self.detection_quality\n",
    "            txt += '\\n---------------------------\\n'\n",
    "            txt += '2nd returns: %6.4f\\n' % self.detection_quality_info['strength_2nd_returns']\n",
    "            txt += 'alignment: %6.4f\\n' % self.detection_quality_info['qual_alignment']\n",
    "            txt += 'depth: %6.4f\\n' % self.detection_quality_info['lake_depth']\n",
    "            txt += 'length: %6.4f\\n' % self.detection_quality_info['lake_length']\n",
    "            txt += 'depth range: %6.4f' % self.detection_quality_info['h_range_2nd_returns']\n",
    "            bbox = {'fc':(1,1,1,0.75), 'ec':(1,1,1,0), 'pad':1}\n",
    "            ax.text(0.99, 0.02, txt, transform=ax.transAxes, ha='right', va='bottom',fontsize=6, weight='bold', bbox=bbox)\n",
    "\n",
    "            fig.patch.set_facecolor('white')\n",
    "            fig.tight_layout()\n",
    "            ax.set_ylim(ylms)\n",
    "            ax.set_xlim(xlms)\n",
    "\n",
    "            # save figure\n",
    "            if not os.path.exists(fig_dir): os.makedirs(fig_dir)\n",
    "            epoch = self.mframe_data['dt'].mean() + datetime.datetime.timestamp(datetime.datetime(2018,1,1))\n",
    "            dateid = datetime.datetime.fromtimestamp(epoch).strftime(\"%Y%m%d-%H%M%S\")\n",
    "            granid = self.granule_id[:-3]\n",
    "            latid = '%dN'%(int(np.round(self.lat*1e5))) if self.lat>=0 else '%dS'%(-int(np.round(self.lat*1e5)))\n",
    "            lonid = '%dE'%(int(np.round(self.lon*1e5))) if self.lon>=0 else '%dW'%(-int(np.round(self.lon*1e5)))\n",
    "\n",
    "            plt.close(fig)\n",
    "\n",
    "            return fig\n",
    "                \n",
    "searchfor = 'lake_'\n",
    "filelist = ['pickles/'+f for f in os.listdir('pickles') \\\n",
    "            if os.path.isfile(os.path.join('pickles', f)) & (searchfor in f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a7e27c3-ca99-4b76-8b2d-4901316ac6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lake_list = []\n",
    "# for filename in sorted(filelist):\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         lk_dict = pickle.load(f)\n",
    "#         lk = dictobj(lk_dict)\n",
    "#         fig = lk.plot_detected(print_mframe_info=True)\n",
    "#         # display(fig)\n",
    "#         figname = 'figs_detection_info/' + filename[filename.rfind('/')+1:].replace('.pkl','.jpg')\n",
    "#         print(figname)\n",
    "#         fig.savefig(figname, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# for dirtozip in ['figs_detection_info']:\n",
    "#     filelist = [dirtozip+'/'+f for f in os.listdir(dirtozip) if os.path.isfile(os.path.join(dirtozip+'/', f))]\n",
    "#     ZipFile = zipfile.ZipFile(\"zip_test_%s.zip\"%dirtozip, \"w\" )\n",
    "#     for file in filelist:\n",
    "#         ZipFile.write(file, compress_type=zipfile.ZIP_DEFLATED)\n",
    "#     ZipFile.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eae8ba69-e093-439c-ba58-12e671b59ac9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c8984-46a3-43d0-b8b7-6e876aaf0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(filelist)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d28de9-dca6-49bb-81c3-15c409aa3e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4160d0-6e41-4ad2-9e3e-12f6c38666eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icepyx-env",
   "language": "python",
   "name": "icepyx-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
