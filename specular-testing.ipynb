{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fb0db1-983f-4d51-9a5b-c98812d6dbce",
   "metadata": {},
   "source": [
    "# Afterpulse Detection (dead-time / internal reflections)\n",
    "To figure out how to detect and remove afterpulses, and plot examples.\n",
    "- use photon rate just around the lake surface elevation (depending on strong/weak beam??)\n",
    "- then use peaks distances that are commonly found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a7fafd-8cb8-4060-8fd7-473d239398a6",
   "metadata": {},
   "source": [
    "### From the literature\n",
    "afterpulses at: ∼0.45, ∼0.9, ∼2.3, and ∼4.2 m\n",
    "\n",
    "The afterpulses captured from on-orbit measurements are caused by three different reasons: (1) the effects of the dead-time circuit (∼3 ns) due to PMT saturation; (2) the effects of optical reflections within the ATLAS receiver optical components; (3) PMT afterpulses. The echoes separated by ∼0.45 m are attributed to the effect of the dead-time circuit (∼3 ns) due to PMT saturation. The echoes at ∼2.3 and ∼4.2 m below the primary surface returns are caused by the optical reflections within the ATLAS receiver optical components, while the echoes from ∼10 to ∼45 m away from the primary surface signal are due to the PMT afterpulses with a longer time delay.\n",
    "\n",
    "Lu, X., Hu, Y., Yang, Y., Vaughan, M., Palm, S., Trepte, C., ... & Baize, R. (2021). Enabling value added scientific applications of ICESat‐2 data with effective removal of afterpulses. Earth and Space Science, 8(6), e2021EA001729."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b197d712-bc64-4ce0-9e4a-6238f7c627b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from IPython.display import Image, display\n",
    "from cmcrameri import cm as cmc\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.signal import find_peaks\n",
    "plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2710c696-4c28-44aa-9bb1-cb50f519de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lake 3 (gt1l, weak)\n",
    "# lake 13* (gt1r, strong)\n",
    "# lake 23 (gt1r, strong)\n",
    "# lake 24 (gt1r, strong)\n",
    "# lake 28 (gt1r, strong)\n",
    "# lake 31** (gt2l, weak)\n",
    "# lake 35** (gt2l, weak)\n",
    "# lake 36** (gt2l, weak)\n",
    "# lake 37** (gt2l, weak)\n",
    "# lake 39*** (gt2l, weak)\n",
    "# lake 43 (gt2r, strong)\n",
    "# lake 44* (gt2r, strong)\n",
    "# lake 45 (gt2r, strong)\n",
    "# lake 46** (gt2r, strong)\n",
    "# lake 48 (gt2r, strong)\n",
    "# lake 50*** (gt2r, strong)\n",
    "# lake 51** (gt2r, strong)\n",
    "# lake 53** (gt2r, strong)\n",
    "# lake 54 (gt2r, strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f33f9442-d993-4332-8e30-29100a9a29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_upper = 1.0\n",
    "thresh_lower = -5.0\n",
    "bin_h=0.01\n",
    "smooth_h=0.1\n",
    "extent_buffer = 20.0\n",
    "smooth_pulse = 11\n",
    "strength = 'strong'\n",
    "\n",
    "cols_pk = ['black','#CD104D', '#E14D2A', '#FD841F', '#8FE3CF', '#256D85']\n",
    "lsty_pk = ['-', '-', '--', ':', '-', ':']\n",
    "elev_pk_lake = [0.0, -0.55, -0.845, -1.36, -2.4, -4.2]\n",
    "elev_pk_puls = [0.0, -0.55, -0.91, -1.465, -2.4, -4.2]\n",
    "widths_pk = [0.225, 0.225, 0.225, 0.225, 0.3, 0.3] # 0.225 m on each side makes it 0.45 total, which is the dead-time for ATLAS\n",
    "df_pks_info = pd.DataFrame({'h_lake': elev_pk_lake, 'h_pulse': elev_pk_puls, 'width': widths_pk, 'color': cols_pk, 'ls': lsty_pk})\n",
    "\n",
    "def group_by_pulse(df_in, smoothing, beam_strength):\n",
    "    thegroup = df_in.groupby('pulseid')\n",
    "    df_grouped = thegroup[['xatc', 'h']].mean()\n",
    "    norm_factor = 4 if beam_strength == 'weak' else 16\n",
    "    df_grouped['ph_count'] = thegroup['h'].count() / norm_factor\n",
    "    df_grouped['ph_count_smooth'] = np.array(df_grouped.ph_count.rolling(smoothing,center=True,min_periods=1).mean())\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634f909-8407-471e-a620-6fa3f7c2f1b4",
   "metadata": {},
   "source": [
    "## get peak elevations from lake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e2a9dfc-c1ac-47d2-952c-bfeb6be23006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8766e763857843f1aba903248e6a337a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "lake_idxs = [3, 13, 23, 24, 28, 31, 35, 36, 37, 39, 43, 44, 45, 46, 48, 50, 51, 53, 54]\n",
    "# lake_idxs = [50]\n",
    "\n",
    "df_list = []\n",
    "# for i in range(71):\n",
    "for i in lake_idxs:\n",
    "    \n",
    "    fn = 'pickles/specular%02i.pkl' % i\n",
    "    with open(fn, 'rb') as f:\n",
    "        lk = pickle.load(f)\n",
    "        \n",
    "    surf_elev = lk['surface_elevation']\n",
    "    df = lk['photon_data']\n",
    "    beam_strength = lk['beam_strength']\n",
    "    dfs = df[(df.h < (thresh_upper+surf_elev)) & (df.h > (thresh_lower+surf_elev))].copy()\n",
    "    dfs['h'] = dfs.h - surf_elev\n",
    "    dfs['pulseid'] = dfs.apply(lambda row: 1000*row.mframe+row.ph_id_pulse, axis=1)\n",
    "    dfs = dfs.set_index('pulseid')\n",
    "    df_surf_photons = dfs[(dfs.h >= -0.25) & (dfs.h < 0.25)].copy()\n",
    "    df_pulses = group_by_pulse(df_surf_photons, smooth_pulse, beam_strength)\n",
    "    df_join = dfs.join(df_pulses, how='left', rsuffix='_pulse')\n",
    "    df_join['h_relative_to_saturated_peak'] = df_join.h - df_join.h_pulse\n",
    "    if (strength not in ['weak','strong']) | (strength == beam_strength):\n",
    "        df_list.append(df_join)\n",
    "    \n",
    "dfs = pd.concat(df_list)\n",
    "df_saturated = dfs[dfs.ph_count_smooth > 0.93]\n",
    "# df_saturated = dfs[dfs.ph_count > 0.99]\n",
    "\n",
    "# histogram binning for afterpulse peaks vs. elevation\n",
    "bins = np.arange(start=thresh_lower, stop=thresh_upper, step=bin_h)\n",
    "mids = bins[:-1] + 0.5 * bin_h\n",
    "smooth = int(smooth_h/bin_h)\n",
    "if smooth %2 == 0: smooth += 1\n",
    "def get_histograms(ph_heights):\n",
    "    hist_h = np.histogram(ph_heights, bins=bins)\n",
    "    hist_h_smooth = np.array(pd.Series(hist_h[0]).rolling(smooth,center=True,min_periods=1).mean())\n",
    "    hist_h_plot = np.array(hist_h[0]) / hist_h_smooth.max()\n",
    "    hist_h_smooth /= hist_h_smooth.max()\n",
    "    return hist_h_plot, hist_h_smooth\n",
    "\n",
    "hist_h_all, hist_h_smooth_all = get_histograms(dfs.h)\n",
    "hist_h_sat, hist_h_smooth_sat = get_histograms(df_saturated.h)\n",
    "hist_h_sat_adjusted, hist_h_smooth_sat_adjusted = get_histograms(df_saturated.h_relative_to_saturated_peak)\n",
    "\n",
    "fig, (ax,ax2) = plt.subplots(ncols=2, figsize=[9, 5], dpi=100)\n",
    "ylms = (thresh_lower, thresh_upper)\n",
    "xlim_ax2 = (1e-4,10)\n",
    "\n",
    "# histogram showing peaks for specular returns\n",
    "ax.scatter(hist_h_all, mids, s=3, color='black', lw=0.5, edgecolors='none', alpha=0.15)\n",
    "ax.plot(hist_h_smooth_all, mids, 'k-', lw=1)\n",
    "ax.set_xlabel('normalized photon counts')\n",
    "ax.set_ylabel('elevation relative to lake surface')\n",
    "ax.set_xlim(xlim_ax2)\n",
    "ax.set_ylim(ylms)\n",
    "ax.set_xscale('log')\n",
    "for i in range(len(df_pks_info)):\n",
    "    thispk = df_pks_info.iloc[i]\n",
    "    thispeak_height = hist_h_smooth_all[np.argmin(np.abs(mids-thispk.h_lake))]\n",
    "    ax.plot([xlim_ax2[0], thispeak_height], [thispk.h_lake]*2, color=thispk.color, ls=thispk.ls, zorder=-1000)\n",
    "    if i == 0:\n",
    "        ax.text(1.1*xlim_ax2[0], thispk.h_lake, 'lake surface', color=thispk.color, ha='left', va='bottom')\n",
    "    else:\n",
    "        ax.text(thispeak_height, thispk.h_lake, '    %.2f m' % thispk.h_lake, color=thispk.color, weight='bold', va='center')\n",
    "\n",
    "\n",
    "ax2.scatter(hist_h_sat_adjusted, mids, s=3, color='black', lw=0.5, edgecolors='none', alpha=0.15)\n",
    "ax2.plot(hist_h_smooth_sat_adjusted, mids, 'k-', lw=1)\n",
    "ax2.set_xlabel('normalized photon counts (saturated pulses only)')\n",
    "ax2.set_ylabel('elevation relative to saturated surface return')\n",
    "ax2.set_xlim(xlim_ax2)\n",
    "ax2.set_ylim(ylms)\n",
    "ax2.set_xscale('log')\n",
    "for i in range(len(df_pks_info)):\n",
    "    thispk = df_pks_info.iloc[i]\n",
    "    thispeak_height = hist_h_smooth_sat_adjusted[np.argmin(np.abs(mids-thispk.h_pulse))]\n",
    "    ax2.plot([xlim_ax2[0], thispeak_height], [thispk.h_pulse]*2, color=thispk.color, ls=thispk.ls, zorder=-1000)\n",
    "    if i == 0:\n",
    "        ax2.text(1.1*xlim_ax2[0], thispk.h_pulse, 'saturated surface return', color=thispk.color, ha='left', va='bottom')\n",
    "    else:\n",
    "        ax2.text(thispeak_height, thispk.h_pulse, '    %.2f m' % thispk.h_pulse, color=thispk.color, weight='bold', va='center')\n",
    "        \n",
    "fig.suptitle('ICESat-2 afterpulses over melt lakes', y=0.98, fontsize=10)\n",
    "fig.tight_layout()\n",
    "\n",
    "figname = 'figs_afterpulses/ICESat-2-afterpulses-melt-lakes-strong-beams.jpg'\n",
    "fig.savefig(figname, dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fad65d-fe91-4112-8a66-ccc99f473e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd14be21-a7a8-4054-82d3-4ca6531c0b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1b6485e85f4797b249cdbe5a088331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "i = 50\n",
    "fn = 'pickles/specular%02i.pkl' % i\n",
    "with open(fn, 'rb') as f:\n",
    "    lk = pickle.load(f)\n",
    "\n",
    "if smooth_pulse%2 == 0: smooth_pulse += 1\n",
    "\n",
    "surf_elev = lk['surface_elevation']\n",
    "surf_ext = lk['surface_extent_detection']\n",
    "df = lk['photon_data']\n",
    "beam_strength = lk['beam_strength']\n",
    "dfs = df[(df.h < (thresh_upper+surf_elev)) & (df.h > (thresh_lower+surf_elev))].copy()\n",
    "dfs['h'] = dfs.h - surf_elev\n",
    "is_in_extent = np.full(len(dfs), False, dtype=np.bool_)\n",
    "for ext in surf_ext:\n",
    "    is_in_extent[(dfs.xatc > (ext[0]-extent_buffer)) & (dfs.xatc < (ext[1]+extent_buffer))] = True\n",
    "dfs = dfs[is_in_extent].copy()\n",
    "\n",
    "# histogram binning for afterpulse peaks vs. elevation\n",
    "bins = np.arange(start=thresh_lower, stop=thresh_upper, step=bin_h)\n",
    "mids = bins[:-1] + 0.5 * bin_h\n",
    "hist_h = np.histogram(dfs.h, bins=bins)\n",
    "smooth = int(smooth_h/bin_h)\n",
    "if smooth %2 == 0: smooth += 1\n",
    "hist_h_smooth = np.array(pd.Series(hist_h[0]).rolling(smooth,center=True,min_periods=1).mean())\n",
    "hist_h_plot = np.array(hist_h[0]) / hist_h_smooth.max()\n",
    "hist_h_smooth /= hist_h_smooth.max()\n",
    "# peaks, peak_props = find_peaks(hist_h_smooth, height=0.1, distance=int(0.4/bin_h_spec), prominence=0.1)\n",
    "\n",
    "# add a unique id for each pulse to group by, then look for per-pulse photon counts\n",
    "dfs['pulseid'] = dfs.apply(lambda row: 1000*row.mframe+row.ph_id_pulse, axis=1)\n",
    "pulse_dfs = []\n",
    "for i in range(len(df_pks_info)):\n",
    "    pkinfo = df_pks_info.iloc[i]\n",
    "    photon_df = dfs[(dfs.h >= (pkinfo.h_lake - pkinfo.width)) & (dfs.h < (pkinfo.h_lake + pkinfo.width))]\n",
    "    pulse_dfs.append(group_by_pulse(photon_df,smooth_pulse,beam_strength))\n",
    "\n",
    "#__________________________________________________________________\n",
    "# make the figure\n",
    "fig, ((ax,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2, figsize=[9, 5], dpi=100)\n",
    "xlms = (surf_ext[0][0], surf_ext[-1][1])\n",
    "ylms = (thresh_lower, thresh_upper)\n",
    "\n",
    "#-------------------------------------------------\n",
    "# selected photons\n",
    "pscatt = ax.scatter(dfs.xatc, dfs.h, s=15, c='k', alpha=0.1, edgecolors='none',label='ATL03 data')\n",
    "ax.scatter(dfs.xatc, dfs.h, s=0.1, c='r', alpha=0.2, edgecolors='none')\n",
    "\n",
    "# title and labels\n",
    "ax.set_xlabel('along-track distance [m]')\n",
    "ax.set_ylabel('elevation from lake surface [m]')\n",
    "ax.set_xlim(xlms)\n",
    "ax.set_ylim(ylms)\n",
    "\n",
    "#-------------------------------------------------\n",
    "# histogram showing peaks for specular returns\n",
    "xlim_ax2 = (1e-4,10)\n",
    "ax2.scatter(hist_h_plot, mids, s=3, color=(0.75, 0.75, 0.75), edgecolors='none')\n",
    "ax2.plot(hist_h_smooth, mids, 'k-', lw=1)\n",
    "# ax2.plot(xlim_ax2, [0]*2, 'b-', lw=0.5)\n",
    "ax2.set_xlabel('normalized photon counts')\n",
    "ax2.set_xlim(xlim_ax2)\n",
    "ax2.set_ylim(ylms)\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "for i in range(len(df_pks_info)):\n",
    "    thispk = df_pks_info.iloc[i]\n",
    "    thispeak_height = hist_h_smooth[np.argmin(np.abs(mids-thispk.h_lake))]\n",
    "    ax2.plot([xlim_ax2[0], thispeak_height], [thispk.h_lake]*2, color=thispk.color, ls=thispk.ls, zorder=-1000)\n",
    "# ax2.axes.yaxis.set_ticklabels([])\n",
    "\n",
    "#-------------------------------------------------\n",
    "# plot photon counts per shot\n",
    "alph = 0.1\n",
    "thisax = ax3\n",
    "def plot_counts(df_in, df_pks_info):\n",
    "    thisax.scatter(df_in.xatc, df_in.ph_count, s=3, color=df_pks_info.iloc[i].color, edgecolors='none', alpha=alph)\n",
    "    thisax.plot(df_in.xatc, df_in.ph_count_smooth, color=df_pks_info.iloc[i].color, ls=df_pks_info.iloc[i].ls)\n",
    "\n",
    "for i,this_peak_pulse_df in enumerate(pulse_dfs):\n",
    "    plot_counts(this_peak_pulse_df, df_pks_info)\n",
    "    \n",
    "ax3.set_xlim(xlms)\n",
    "ax3.set_yscale('log')\n",
    "         \n",
    "#-------------------------------------------------\n",
    "# the full lake, for reference\n",
    "ax4.scatter(df.xatc, df.h, s=6, c=df.snr, alpha=0.3, edgecolors='none', cmap=cmc.lajolla, vmin=0, vmax=1)\n",
    "rng = np.abs(surf_elev-np.min(lk['detection_2nd_returns']['h']))\n",
    "ax4.set_xlim((df.xatc.min(),df.xatc.max()))\n",
    "ax4.set_ylim((surf_elev-2*rng, surf_elev+rng))\n",
    "\n",
    "fig.suptitle('example of specular return afterpulses over a melt lake in ICESat-2 data', y=0.98, fontsize=10)\n",
    "fig.tight_layout()\n",
    "\n",
    "figname = 'figs_afterpulses/afterpulse_example_lake.jpg'\n",
    "fig.savefig(figname, dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2790bc5-2790-49b2-bcf7-aeb6723e5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_group = dfs.groupby('pulseid')\n",
    "df_pulse = pulse_group[['xatc', 'lat', 'lon']].mean()\n",
    "df_pulse['ph_count'] = pulse_group['h'].count()\n",
    "df_pulse['ph_count_smooth'] = np.array(df_pulse.ph_count.rolling(smooth_pulse,center=True,min_periods=1).mean())\n",
    "\n",
    "pulse_group_top = df_top.groupby('pulseid')\n",
    "df_pulse_top = pulse_group_top[['xatc', 'lat', 'lon']].mean()\n",
    "df_pulse_top['ph_count'] = pulse_group_top['h'].count()\n",
    "df_pulse_top['ph_count_smooth'] = np.array(df_pulse_top.ph_count.rolling(smooth_pulse,center=True,min_periods=1).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b451eba-2260-43a9-b558-adf19c982aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578a6ec-b931-4981-8916-cec6a9720d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ff335-ed53-48f6-890e-3da683573ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mframe_group = df.groupby('mframe')\n",
    "    df_mframe = mframe_group[['lat','lon', 'xatc', 'dt']].mean()\n",
    "    df_mframe.drop(df_mframe.head(1).index,inplace=True)\n",
    "    df_mframe.drop(df_mframe.tail(1).index,inplace=True)\n",
    "    df_mframe['time'] = df_mframe['dt'].map(convert_time_to_string)\n",
    "    df_mframe['xatc_min'] = mframe_group['xatc'].min()\n",
    "    df_mframe['xatc_max'] = mframe_group['xatc'].max()\n",
    "    df_mframe['n_phot'] = mframe_group['h'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf261a8-f5f9-473a-8457-4557fd5b7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulse_dfs[0].loc[pulse_dfs[0].iloc[:5].index]\n",
    "df_pulses = pulse_dfs[0]\n",
    "idx1 = df_pulses[df_pulses.ph_count > 0.99].index\n",
    "idx2 = df_pulses[df_pulses.ph_count > 0.99].index\n",
    "idx1.append(idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28d14d-6478-4e44-96d1-081eb5f74baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663c10a-9a7b-445c-ab40-5f7a5c7f3695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070abf89-6b10-48c1-938e-e1076d28382e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa7c1c-75c2-486b-986e-ebbd1f361f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lk['photon_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d60701-4ea9-4356-abd1-0e190ec4e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_xlim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce005d-ca3b-48d4-bf97-ac7b6ec4068f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc42a2-ed04-4769-b154-1c9a156619cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5aecf-4953-4a47-ac5c-553dae4a0dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417f79b-a646-4834-ad40-2d3941478071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icepyx-env",
   "language": "python",
   "name": "icepyx-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
