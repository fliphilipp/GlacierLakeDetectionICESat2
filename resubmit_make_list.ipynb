{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef4073d-579d-4ee6-a824-8c63733c178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a7a1f56-165f-4e72-bfb2-5edcb990bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_granule_list(input_list):\n",
    "    df = pd.read_csv(input_list, header=None, names=['fn','hold_reason'])\n",
    "    df['is_memory'] = df.apply(lambda x: 'exceeded request_memory' in x.hold_reason, axis=1)\n",
    "    df['granule'] = df.apply(lambda x: x.fn[x.fn.find('ATL03_'):x.fn.find('.h5')+3], axis=1)\n",
    "    def get_description(x):\n",
    "        substr = x.fn[x.fn.find('job_')+4:x.fn.find('_ATL03_')]\n",
    "        return substr[:substr.rfind('-')]\n",
    "    df['description'] = df.apply(get_description, axis=1)\n",
    "    def get_geojson(x):\n",
    "        parms = x.description.split('_')\n",
    "        parms[0] = 'ANT' if parms[0] == 'AIS' else 'GRE'\n",
    "        del parms[1]\n",
    "        return 'geojsons/simplified_' + '_'.join(parms) + '.geojson'\n",
    "    df['geojson'] = df.apply(get_geojson, axis=1)\n",
    "    df['geojson_full'] = df.apply(lambda x: x.geojson.replace('simplified_', ''), axis=1)\n",
    "    df = df[['granule','geojson','description','geojson_full','fn','hold_reason','is_memory']]\n",
    "    df.to_csv(input_list.replace('.csv', '_processed.csv'))\n",
    "    \n",
    "    df_mem = df[df.is_memory]\n",
    "    df_nomem = df[~df.is_memory]\n",
    "    \n",
    "    df_mem = df_mem.drop(columns=['fn','hold_reason','is_memory'])\n",
    "    df_nomem = df_nomem.drop(columns=['fn','hold_reason','is_memory'])\n",
    "    \n",
    "    fn_mem = input_list.replace('hold_lists/', 'granule_lists/').replace('final_', 'memory_')\n",
    "    fn_nomem = input_list.replace('hold_lists/', 'granule_lists/').replace('final_', 'resubmit_')\n",
    "    \n",
    "    df_mem.to_csv(fn_mem, header=False, index=False)\n",
    "    print('Wrote file %s. (%i jobs)' % (fn_mem, len(df_mem)))\n",
    "    df_nomem.to_csv(fn_nomem, header=False, index=False)\n",
    "    print('Wrote file %s. (%i jobs)' % (fn_nomem, len(df_nomem)))\n",
    "\n",
    "    return fn_mem, fn_nomem\n",
    "\n",
    "def write_submit_file(list_fn, sub_fn=None, mem_gb=16): \n",
    "    if not sub_fn:\n",
    "        sub_fn = list_fn.replace('granule_lists/', 'HTCondor_submit/').replace('.csv', '.submit')\n",
    "    \n",
    "    f = open(sub_fn, \"w\")\n",
    "    print('universe    = vanilla', file=f)\n",
    "    print('+SingularityImage = \"osdf:///ospool/ap21/data/fliphilipp/containers/icelake-container_v1.sif\"', file=f)\n",
    "    print('Requirements = HAS_SINGULARITY == True && OSG_HOST_KERNEL_VERSION >= 31000', file=f)\n",
    "    print('executable  = run_py.sh', file=f)\n",
    "    print('arguments = $(granule) $(polygon)', file=f)\n",
    "    print('max_retries = 10', file=f)\n",
    "    print('success_exit_code = 69', file=f)\n",
    "    print('transfer_input_files = detect_lakes.py, icelakes/__init__.py, icelakes/utilities.py, icelakes/nsidc.py, icelakes/detection.py, misc/test1, misc/test2, $(polygon), $(polygon_full)', file=f)\n",
    "    print('transfer_output_files = detection_out_data, detection_out_plot, detection_out_stat', file=f)\n",
    "    print('should_transfer_files = YES', file=f)\n",
    "    print('when_to_transfer_output = ON_EXIT', file=f)\n",
    "    print('log           = logs/job_$(descriptor)-$(ClusterID)_$(granule)-$(ProcID).log', file=f)\n",
    "    print('error         = errs/job_$(descriptor)-$(ClusterID)_$(granule)-$(ProcID).err', file=f)\n",
    "    print('output        = outs/job_$(descriptor)-$(ClusterID)_$(granule)-$(ProcID).out', file=f)\n",
    "    print('request_cpus    = 1', file=f)\n",
    "    print('request_memory  = %iGB' % mem_gb, file=f)\n",
    "    print('request_disk    = %iGB' % mem_gb, file=f)\n",
    "    print('queue granule,polygon,descriptor,polygon_full from %s' % list_fn, file=f)\n",
    "    f.close()\n",
    "    \n",
    "    print('Wrote file %s.\\n' % sub_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47e6abe-6685-4900-bfa8-b82562771968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file granule_lists/memory_greenland-1-114211.csv. (63 jobs)\n",
      "Wrote file granule_lists/resubmit_greenland-1-114211.csv. (3537 jobs)\n",
      "Wrote file HTCondor_submit/resubmit_greenland-1-114211.submit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_list = 'hold_lists/final_greenland-1-114211.csv'\n",
    "fn_mem, fn_nomem = write_granule_list(input_list)\n",
    "write_submit_file(fn_nomem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86846bf2-9a4b-4cc3-bdfd-bb581c8b8534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file granule_lists/memory_antarctica-18-21-1-114218.csv. (83 jobs)\n",
      "Wrote file granule_lists/resubmit_antarctica-18-21-1-114218.csv. (9077 jobs)\n",
      "Wrote file HTCondor_submit/resubmit_antarctica-18-21-1-114218.submit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_list = 'hold_lists/final_antarctica-18-21-1-114218.csv'\n",
    "fn_mem, fn_nomem = write_granule_list(input_list)\n",
    "write_submit_file(fn_nomem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ace1c9f-b18c-456b-aa15-121bb7a0f206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file granule_lists/memory_antarctica-21-23-1-114219.csv. (0 jobs)\n",
      "Wrote file granule_lists/resubmit_antarctica-21-23-1-114219.csv. (3848 jobs)\n",
      "Wrote file HTCondor_submit/resubmit_antarctica-21-23-1-114219.submit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_list = 'hold_lists/final_antarctica-21-23-1-114219.csv'\n",
    "fn_mem, fn_nomem = write_granule_list(input_list)\n",
    "write_submit_file(fn_nomem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5973a71-2644-4e19-b164-c6b54152e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file granule_lists/memory_greenland-2-117771.csv. (77 jobs)\n",
      "Wrote file granule_lists/resubmit_greenland-2-117771.csv. (423 jobs)\n",
      "Wrote file HTCondor_submit/resubmit_greenland-2-117771.submit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_list = 'hold_lists/final_greenland-2-117771.csv'\n",
    "fn_mem, fn_nomem = write_granule_list(input_list)\n",
    "write_submit_file(fn_nomem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e624d4-013c-4783-b39c-d8fd5eadf64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b4c0e-30cc-4c63-a157-49045f0f31a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334de01-6af9-4e82-8dcf-5fd61c96b42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icelakes-env",
   "language": "python",
   "name": "icelakes-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
