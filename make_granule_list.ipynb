{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20db82b2-14e2-41bf-9120-76a4784859f3",
   "metadata": {},
   "source": [
    "# Make Granule List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93a001c-dbf8-4a15-bade-8a059b1e1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utility function for making granule list\n",
    "from icelakes.nsidc import make_granule_list\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.polygon import orient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f3d5e-d7b6-4584-8e36-d047038c7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to convert shapefile to geojson - if needed\n",
    "# shp2geojson_nsidc('shapefiles/jakobshavn_small.shp')\n",
    "\n",
    "lons = [-154, -153]\n",
    "lats = [-85.46, -85.41]\n",
    "\n",
    "coords = [(lons[x[0]], lats[x[1]]) for x in [(0,0), (1,0), (1,1), (0,1), (0,0)]]\n",
    "poly = Polygon(coords)\n",
    "gdf = gpd.GeoDataFrame(geometry=[poly], crs='EPSG:4326') \n",
    "fn_gjsn = 'geojsons/test_ross.geojson'\n",
    "gdf.to_file(fn_gjsn, driver='GeoJSON')\n",
    "outname_list = fn_gjsn.split('/')[-1].replace('.geojson','.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f59a5a-4a52-460e-8ee5-098b74f5159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429121f9-9bbb-4db7-97f1-106d13f05a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_granule_list(fn_gjsn.split('/')[-1], start_date='2022-01-04', end_date='2022-01-04', \n",
    "                       icesheet='AIS', meltseason='2021-22', list_out_name=outname_list,\n",
    "                       version=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0791904-f2c3-40ca-bb83-047e6e4b3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "'granule_lists/GRE_2000_May2019_Jun2023.csv'\n",
    "'granule_lists/ANT_1000_Dec2018_Mar2021.csv'\n",
    "'granule_lists/ANT_1000_Dec2021_Mar2023.csv'\n",
    "'granule_lists/GRE_2000_extraMaySep.csv'\n",
    "'granule_lists/GRE_2000_May2023_Sep2023_newdata.csv'\n",
    "\n",
    "'granule_lists/alldata_2018-2023.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e262b-7860-4c77-80c3-91e4dd362921",
   "metadata": {},
   "source": [
    "# Greenland 2023 (new data only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "011f4e24-f926-47a4-a1bc-dc21e3da43ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________\n",
      "GREENLAND 2023\n",
      "____________________________________________________________________________\n",
      "----------------------------------------------------------------\n",
      "simplified_GRE_2000_NE.geojson ( 1 / 7 )\n",
      "Found 391 ATL03 version 006 granules over simplified_GRE_2000_NE.geojson between 2023-05-01 and 2023-09-30.\n",
      "----------------------------------------------------------------\n",
      "simplified_GRE_2000_SW.geojson ( 2 / 7 )\n",
      "Found 97 ATL03 version 006 granules over simplified_GRE_2000_SW.geojson between 2023-05-01 and 2023-09-30.\n",
      "----------------------------------------------------------------\n",
      "simplified_GRE_2000_CE.geojson ( 3 / 7 )\n",
      "Found 184 ATL03 version 006 granules over simplified_GRE_2000_CE.geojson between 2023-05-01 and 2023-09-30.\n",
      "----------------------------------------------------------------\n",
      "simplified_GRE_2000_NO.geojson ( 4 / 7 )\n",
      "Found 883 ATL03 version 006 granules over simplified_GRE_2000_NO.geojson between 2023-05-01 and 2023-09-30.\n",
      "----------------------------------------------------------------\n",
      "simplified_GRE_2000_SE.geojson ( 5 / 7 )\n",
      "Found 130 ATL03 version 006 granules over simplified_GRE_2000_SE.geojson between 2023-05-01 and 2023-09-30.\n",
      "----------------------------------------------------------------\n",
      "simplified_GRE_2000_NW.geojson ( 6 / 7 )\n",
      "Found 292 ATL03 version 006 granules over simplified_GRE_2000_NW.geojson between 2023-05-01 and 2023-09-30.\n",
      "----------------------------------------------------------------\n",
      "simplified_GRE_2000_CW.geojson ( 7 / 7 )\n",
      "Found 91 ATL03 version 006 granules over simplified_GRE_2000_CW.geojson between 2023-05-01 and 2023-09-30.\n",
      "Number of ganules over Greenland: 1374\n",
      "Number of ganules over Antarctica: 0\n",
      "Total number of granules: 1374\n",
      "Largest granule: 7.5 GB, ATL03_20230630192302_01622005_006_02.h5, geojsons/simplified_GRE_2000_NE.geojson\n",
      "Total size: 3.24 TB\n",
      "____________________________________________________________________________\n",
      "ALL DATA COMBINED\n",
      "Number of ganules over Greenland: 10136\n",
      "Number of ganules over Antarctica: 42753\n",
      "Total number of granules: 52889\n",
      "Largest granule: 12.2 GB, ATL03_20220511191525_07591505_006_01.h5, geojsons/simplified_GRE_2000_NO.geojson\n",
      "Total size: 135.50 TB\n"
     ]
    }
   ],
   "source": [
    "filename_new = 'granule_lists/GRE_2000_May2023_Sep2023_newdata.csv'\n",
    "filename_all = 'granule_lists/alldata_2018-2023.csv'\n",
    "\n",
    "startyear = 2023\n",
    "endyear = 2023\n",
    "startday = '05-01'\n",
    "endday = '09-30'\n",
    "icesheet = 'GrIS'\n",
    "\n",
    "searchfor = 'simplified_GRE_2000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "print('____________________________________________________________________________')\n",
    "print('GREENLAND 2023')\n",
    "print('____________________________________________________________________________')\n",
    "\n",
    "dflist = []\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear+1):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "\n",
    "def filter_release(df):\n",
    "    # there should not be any, but to make sure drop any duplicates\n",
    "    df = df.drop_duplicates(ignore_index=True)\n",
    "    \n",
    "    # keep only the latest release of each granule (relevant during ITRF reprocessing, etc.)\n",
    "    df['release'] = df.apply(lambda x: int(x.granule.split('_')[-1][:2]), axis=1)\n",
    "    df['version'] = df.apply(lambda x: int(x.granule.split('_')[3]), axis=1)\n",
    "    df['ttttccnn'] = df.apply(lambda x: int(x.granule.split('_')[2]), axis=1)\n",
    "    \n",
    "    # make id for granule / region combination\n",
    "    df['granule_region_id'] = df.apply(lambda x: str(x.ttttccnn) + x.geojson_clip, axis=1)\n",
    "    df_maxversion = df.groupby(by='granule_region_id')[['version']].max().rename(columns={'version': 'version_max'})\n",
    "    df['select'] = df.apply(lambda x: x.version == df_maxversion.loc[x.granule_region_id].version_max, axis=1)\n",
    "    df = df[df.select]\n",
    "    df_maxrelease = df.groupby(by='granule_region_id')[['release']].max().rename(columns={'release': 'release_max'})\n",
    "    df['select'] = df.apply(lambda x: x.release == df_maxrelease.loc[x.granule_region_id].release_max, axis=1)\n",
    "    df = df[df.select]\n",
    "\n",
    "    return df\n",
    "\n",
    "# get the granules that have already been procesed\n",
    "in_list = [\n",
    "    'granule_lists/GRE_2000_May2019_Jun2023.csv',\n",
    "    'granule_lists/ANT_1000_Dec2018_Mar2021.csv',\n",
    "    'granule_lists/ANT_1000_Dec2021_Mar2023.csv',\n",
    "    'granule_lists/extra_shoulderseason_GRE_2000_ANT_1000.csv']\n",
    "nms = ['granule', 'geojson', 'description', 'geojson_clip', 'size_mb']\n",
    "dfs_all_input = []\n",
    "for grlist in in_list:\n",
    "    dfs_all_input.append(pd.read_csv(grlist.replace('.csv', '_size.csv'), header=None, names=nms))\n",
    "df_processed = pd.concat(dfs_all_input).reset_index(drop=True)\n",
    "df_already_run = filter_release(df_processed)\n",
    "\n",
    "df_new = filter_release(df_all)\n",
    "ids_run_already = list(df_already_run.granule_region_id)\n",
    "df_new['select'] = df_new.apply(lambda x: x.granule_region_id not in ids_run_already, axis=1)\n",
    "df_new = df_new[df_new.select].reset_index(drop=True)\n",
    "df_new.iloc[:,:5]\n",
    "df_new.iloc[:,:5].to_csv(filename_new.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_new.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_new.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_new))\n",
    "maxrow = df_new.loc[np.argmax(df_new.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_new.size_mb)/1e6))\n",
    "\n",
    "df_new_nosize = df_new.iloc[:,:4].copy()\n",
    "df_new_nosize.to_csv(filename_new, header=False, index=False)\n",
    "\n",
    "print('____________________________________________________________________________')\n",
    "print('ALL DATA COMBINED')\n",
    "df_everything = pd.concat((df_new, df_already_run)).drop_duplicates(ignore_index=True, subset=['granule_region_id']).sort_values(by='granule').reset_index(drop=True)\n",
    "print('Number of ganules over Greenland:', np.sum(df_everything.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_everything.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_everything))\n",
    "maxrow = df_everything.loc[np.argmax(df_everything.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_everything.size_mb)/1e6))\n",
    "\n",
    "df_everything.iloc[:,:5].to_csv(filename_all.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "df_everything_nosize = df_everything.iloc[:,:4].copy()\n",
    "df_everything_nosize.to_csv(filename_all, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064e8fe-ae94-40d8-b5c2-0c17cb62fc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025018ef-3486-4bf9-b350-dc7d01675fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfa4a4-ad94-4b68-be44-ce7c6fc6e4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d69c9-a8c6-4611-b946-13e056757884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0d84f80-154e-412d-afd5-53611b5c8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_release(df):\n",
    "    # there should not be any, but to make sure drop any duplicates\n",
    "    df = df.drop_duplicates(ignore_index=True)\n",
    "    \n",
    "    # keep only the latest release of each granule (relevant during ITRF reprocessing, etc.)\n",
    "    df['release'] = df.apply(lambda x: int(x.granule.split('_')[-1][:2]), axis=1)\n",
    "    df['version'] = df.apply(lambda x: int(x.granule.split('_')[3]), axis=1)\n",
    "    df['ttttccnn'] = df.apply(lambda x: int(x.granule.split('_')[2]), axis=1)\n",
    "    \n",
    "    # make id for granule / region combination\n",
    "    df['granule_region_id'] = df.apply(lambda x: str(x.ttttccnn) + x.geojson_clip, axis=1)\n",
    "    df_maxversion = df.groupby(by='granule_region_id')[['version']].max().rename(columns={'version': 'version_max'})\n",
    "    df['select'] = df.apply(lambda x: x.version == df_maxversion.loc[x.granule_region_id].version_max, axis=1)\n",
    "    df = df[df.select]\n",
    "    df_maxrelease = df.groupby(by='granule_region_id')[['release']].max().rename(columns={'release': 'release_max'})\n",
    "    df['select'] = df.apply(lambda x: x.release == df_maxrelease.loc[x.granule_region_id].release_max, axis=1)\n",
    "    df = df[df.select]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0489417-be08-46ea-9a53-4c3fa895d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the granules that have already been procesed\n",
    "in_list = [\n",
    "    'granule_lists/GRE_2000_May2019_Jun2023.csv',\n",
    "    'granule_lists/ANT_1000_Dec2018_Mar2021.csv',\n",
    "    'granule_lists/ANT_1000_Dec2021_Mar2023.csv',\n",
    "    'granule_lists/extra_shoulderseason_GRE_2000_ANT_1000.csv']\n",
    "nms = ['granule', 'geojson', 'description', 'geojson_clip', 'size_mb']\n",
    "dfs_all_input = []\n",
    "for grlist in in_list:\n",
    "    dfs_all_input.append(pd.read_csv(grlist.replace('.csv', '_size.csv'), header=None, names=nms))\n",
    "df_processed = pd.concat(dfs_all_input).reset_index(drop=True)\n",
    "df_already_run = filter_release(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5105d1e8-5eb9-4e46-af84-350c71fc7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = df_already_run.groupby('granule_region_id')[['granule']].count().rename(columns={'granule': 'counts'})\n",
    "# counts = counts[counts.counts > 1]\n",
    "# for i in range(len(counts)):\n",
    "#     thisdf = df_already_run[df_already_run.granule_region_id == list(counts.index)[0]]\n",
    "#     print(' ')\n",
    "#     for j in range(len(thisdf)):\n",
    "#         x = thisdf.iloc[j]\n",
    "#         print(x.granule, x.geojson, x.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84f2b32d-39c7-4c5e-bff3-d7ad5d426b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ganules over Greenland: 1374\n",
      "Number of ganules over Antarctica: 0\n",
      "Total number of granules: 1374\n",
      "Largest granule: 7.5 GB, ATL03_20230630192302_01622005_006_02.h5, geojsons/simplified_GRE_2000_NE.geojson\n",
      "Total size: 3.24 TB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granule</th>\n",
       "      <th>geojson</th>\n",
       "      <th>description</th>\n",
       "      <th>geojson_clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL03_20230622065452_00322003_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL03_20230622070018_00322004_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL03_20230623062913_00472003_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL03_20230623204315_00562004_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL03_20230623204824_00562005_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>ATL03_20230921165327_00412105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>ATL03_20230925040010_00942103_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>ATL03_20230925164503_01022105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>ATL03_20230929035148_01552103_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>ATL03_20230929163640_01632105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1374 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      granule  \\\n",
       "0     ATL03_20230622065452_00322003_006_02.h5   \n",
       "1     ATL03_20230622070018_00322004_006_02.h5   \n",
       "2     ATL03_20230623062913_00472003_006_02.h5   \n",
       "3     ATL03_20230623204315_00562004_006_02.h5   \n",
       "4     ATL03_20230623204824_00562005_006_02.h5   \n",
       "...                                       ...   \n",
       "1369  ATL03_20230921165327_00412105_006_02.h5   \n",
       "1370  ATL03_20230925040010_00942103_006_02.h5   \n",
       "1371  ATL03_20230925164503_01022105_006_02.h5   \n",
       "1372  ATL03_20230929035148_01552103_006_02.h5   \n",
       "1373  ATL03_20230929163640_01632105_006_02.h5   \n",
       "\n",
       "                                      geojson        description  \\\n",
       "0     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "1     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "2     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "3     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "4     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "...                                       ...                ...   \n",
       "1369  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "1370  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "1371  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "1372  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "1373  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "\n",
       "                      geojson_clip  \n",
       "0     geojsons/GRE_2000_NE.geojson  \n",
       "1     geojsons/GRE_2000_NE.geojson  \n",
       "2     geojsons/GRE_2000_NE.geojson  \n",
       "3     geojsons/GRE_2000_NE.geojson  \n",
       "4     geojsons/GRE_2000_NE.geojson  \n",
       "...                            ...  \n",
       "1369  geojsons/GRE_2000_CW.geojson  \n",
       "1370  geojsons/GRE_2000_CW.geojson  \n",
       "1371  geojsons/GRE_2000_CW.geojson  \n",
       "1372  geojsons/GRE_2000_CW.geojson  \n",
       "1373  geojsons/GRE_2000_CW.geojson  \n",
       "\n",
       "[1374 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_out = 'granule_lists/GRE_2000_May2023_Sep2023_newdata.csv'\n",
    "\n",
    "df_new = filter_release(df_all)\n",
    "ids_run_already = list(df_already_run.granule_region_id)\n",
    "df_new['select'] = df_new.apply(lambda x: x.granule_region_id not in ids_run_already, axis=1)\n",
    "df_new = df_new[df_new.select].reset_index(drop=True)\n",
    "df_new.iloc[:,:5]\n",
    "df_new.iloc[:,:5].to_csv(filename_out.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_new.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_new.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_new))\n",
    "maxrow = df_new.loc[np.argmax(df_new.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_new.size_mb)/1e6))\n",
    "\n",
    "df_new_nosize = df_new.iloc[:,:4].copy()\n",
    "df_new_nosize.to_csv(filename_out, header=False, index=False)\n",
    "\n",
    "filename_all = 'granule_lists/alldata_2018-2023.csv'\n",
    "df_everything = pd.concat((df_new, df_already_run)).drop_duplicates(ignore_index=True, subset=['granule_region_id']).sort_values(by='granule').reset_index(drop=True)\n",
    "print('Number of ganules over Greenland:', np.sum(df_everything.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_everything.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_everything))\n",
    "maxrow = df_everything.loc[np.argmax(df_everything.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_everything.size_mb)/1e6))\n",
    "\n",
    "df_everything.iloc[:,:5].to_csv(filename_all.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "df_everything_nosize = df_everything.iloc[:,:4].copy()\n",
    "df_everything_nosize.to_csv(filename_all, header=False, index=False)\n",
    "df_everything_nosize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "327db1d7-a35f-4685-a76b-90bcaa5f20c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ganules over Greenland: 10136\n",
      "Number of ganules over Antarctica: 42753\n",
      "Total number of granules: 52889\n",
      "Largest granule: 12.2 GB, ATL03_20220511191525_07591505_006_01.h5, geojsons/simplified_GRE_2000_NO.geojson\n",
      "Total size: 135.50 TB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granule</th>\n",
       "      <th>geojson</th>\n",
       "      <th>description</th>\n",
       "      <th>geojson_clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL03_20181031235247_05090112_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_West_F-G.geojson</td>\n",
       "      <td>AIS_2018_1000_West_F-G</td>\n",
       "      <td>geojsons/ANT_1000_West_F-G.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL03_20181101024758_05110110_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_East_K-A.geojson</td>\n",
       "      <td>AIS_2018_1000_East_K-A</td>\n",
       "      <td>geojsons/ANT_1000_East_K-A.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL03_20181101025539_05110111_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>AIS_2018_1000_West_Ep-F</td>\n",
       "      <td>geojsons/ANT_1000_West_Ep-F.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL03_20181101030122_05110112_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>AIS_2018_1000_West_Ep-F</td>\n",
       "      <td>geojsons/ANT_1000_West_Ep-F.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL03_20181101042215_05120110_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_East_K-A.geojson</td>\n",
       "      <td>AIS_2018_1000_East_K-A</td>\n",
       "      <td>geojsons/ANT_1000_East_K-A.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52884</th>\n",
       "      <td>ATL03_20230930161101_01782105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NO.geojson</td>\n",
       "      <td>GrIS_2023_2000_NO</td>\n",
       "      <td>geojsons/GRE_2000_NO.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52885</th>\n",
       "      <td>ATL03_20230930161101_01782105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52886</th>\n",
       "      <td>ATL03_20230930174010_01792104_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NO.geojson</td>\n",
       "      <td>GrIS_2023_2000_NO</td>\n",
       "      <td>geojsons/GRE_2000_NO.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52887</th>\n",
       "      <td>ATL03_20230930174519_01792105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NO.geojson</td>\n",
       "      <td>GrIS_2023_2000_NO</td>\n",
       "      <td>geojsons/GRE_2000_NO.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52888</th>\n",
       "      <td>ATL03_20230930174519_01792105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NW.geojson</td>\n",
       "      <td>GrIS_2023_2000_NW</td>\n",
       "      <td>geojsons/GRE_2000_NW.geojson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52889 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       granule  \\\n",
       "0      ATL03_20181031235247_05090112_006_02.h5   \n",
       "1      ATL03_20181101024758_05110110_006_02.h5   \n",
       "2      ATL03_20181101025539_05110111_006_02.h5   \n",
       "3      ATL03_20181101030122_05110112_006_02.h5   \n",
       "4      ATL03_20181101042215_05120110_006_02.h5   \n",
       "...                                        ...   \n",
       "52884  ATL03_20230930161101_01782105_006_02.h5   \n",
       "52885  ATL03_20230930161101_01782105_006_02.h5   \n",
       "52886  ATL03_20230930174010_01792104_006_02.h5   \n",
       "52887  ATL03_20230930174519_01792105_006_02.h5   \n",
       "52888  ATL03_20230930174519_01792105_006_02.h5   \n",
       "\n",
       "                                              geojson  \\\n",
       "0       geojsons/simplified_ANT_1000_West_F-G.geojson   \n",
       "1       geojsons/simplified_ANT_1000_East_K-A.geojson   \n",
       "2      geojsons/simplified_ANT_1000_West_Ep-F.geojson   \n",
       "3      geojsons/simplified_ANT_1000_West_Ep-F.geojson   \n",
       "4       geojsons/simplified_ANT_1000_East_K-A.geojson   \n",
       "...                                               ...   \n",
       "52884         geojsons/simplified_GRE_2000_NO.geojson   \n",
       "52885         geojsons/simplified_GRE_2000_NE.geojson   \n",
       "52886         geojsons/simplified_GRE_2000_NO.geojson   \n",
       "52887         geojsons/simplified_GRE_2000_NO.geojson   \n",
       "52888         geojsons/simplified_GRE_2000_NW.geojson   \n",
       "\n",
       "                   description                         geojson_clip  \n",
       "0       AIS_2018_1000_West_F-G   geojsons/ANT_1000_West_F-G.geojson  \n",
       "1       AIS_2018_1000_East_K-A   geojsons/ANT_1000_East_K-A.geojson  \n",
       "2      AIS_2018_1000_West_Ep-F  geojsons/ANT_1000_West_Ep-F.geojson  \n",
       "3      AIS_2018_1000_West_Ep-F  geojsons/ANT_1000_West_Ep-F.geojson  \n",
       "4       AIS_2018_1000_East_K-A   geojsons/ANT_1000_East_K-A.geojson  \n",
       "...                        ...                                  ...  \n",
       "52884        GrIS_2023_2000_NO         geojsons/GRE_2000_NO.geojson  \n",
       "52885        GrIS_2023_2000_NE         geojsons/GRE_2000_NE.geojson  \n",
       "52886        GrIS_2023_2000_NO         geojsons/GRE_2000_NO.geojson  \n",
       "52887        GrIS_2023_2000_NO         geojsons/GRE_2000_NO.geojson  \n",
       "52888        GrIS_2023_2000_NW         geojsons/GRE_2000_NW.geojson  \n",
       "\n",
       "[52889 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_all = 'granule_lists/alldata_2018-2023.csv'\n",
    "df_everything = pd.concat((df_new, df_already_run)).drop_duplicates(ignore_index=True, subset=['granule_region_id']).sort_values(by='granule').reset_index(drop=True)\n",
    "print('Number of ganules over Greenland:', np.sum(df_everything.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_everything.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_everything))\n",
    "maxrow = df_everything.loc[np.argmax(df_everything.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_everything.size_mb)/1e6))\n",
    "\n",
    "df_everything.iloc[:,:5].to_csv(filename_all.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "df_everything_nosize = df_everything.iloc[:,:4].copy()\n",
    "df_everything_nosize.to_csv(filename_all, header=False, index=False)\n",
    "df_everything_nosize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc0690-3c42-48cc-bb1f-e2720ee81df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8906567-c722-4c34-8a66-b2e40b8d3928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46599baf-bce8-4852-a26b-d2bf199f08e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6da8b38e-7745-4925-917b-02281772460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51814 51515\n"
     ]
    }
   ],
   "source": [
    "print(len(df_already_run.granule_region_id), len(np.unique(df_already_run.granule_region_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aec6b87e-5496-4e50-a8e0-406488144845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'272005geojsons/GRE_2000_NO.geojson' in list(df_already_run.granule_region_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33801b3b-2f11-4e87-b75e-d359444d2418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granule</th>\n",
       "      <th>geojson</th>\n",
       "      <th>description</th>\n",
       "      <th>geojson_clip</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>granule_norelease</th>\n",
       "      <th>release</th>\n",
       "      <th>version</th>\n",
       "      <th>ttttccnn</th>\n",
       "      <th>granule_region_id</th>\n",
       "      <th>select</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL03_20230501225732_06351904_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>2336.841153</td>\n",
       "      <td>ATL03_20230501225732_06351904_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6351904</td>\n",
       "      <td>6351904geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL03_20230501230241_06351905_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>1538.320868</td>\n",
       "      <td>ATL03_20230501230241_06351905_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6351905</td>\n",
       "      <td>6351905geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL03_20230502223152_06501904_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>1913.935168</td>\n",
       "      <td>ATL03_20230502223152_06501904_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6501904</td>\n",
       "      <td>6501904geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL03_20230502223701_06501905_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>1979.593719</td>\n",
       "      <td>ATL03_20230502223701_06501905_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6501905</td>\n",
       "      <td>6501905geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL03_20230503092628_06571903_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NE.geojson</td>\n",
       "      <td>GrIS_2023_2000_NE</td>\n",
       "      <td>geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>7311.369440</td>\n",
       "      <td>ATL03_20230503092628_06571903_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6571903</td>\n",
       "      <td>6571903geojsons/GRE_2000_NE.geojson</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>ATL03_20230921165327_00412105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>3272.413673</td>\n",
       "      <td>ATL03_20230921165327_00412105_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>412105</td>\n",
       "      <td>412105geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>ATL03_20230925040010_00942103_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>501.831805</td>\n",
       "      <td>ATL03_20230925040010_00942103_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>942103</td>\n",
       "      <td>942103geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>ATL03_20230925164503_01022105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>2889.815962</td>\n",
       "      <td>ATL03_20230925164503_01022105_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1022105</td>\n",
       "      <td>1022105geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>ATL03_20230929035148_01552103_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>833.089432</td>\n",
       "      <td>ATL03_20230929035148_01552103_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1552103</td>\n",
       "      <td>1552103geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>ATL03_20230929163640_01632105_006_02.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>2530.250005</td>\n",
       "      <td>ATL03_20230929163640_01632105_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1632105</td>\n",
       "      <td>1632105geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2068 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      granule  \\\n",
       "0     ATL03_20230501225732_06351904_006_02.h5   \n",
       "1     ATL03_20230501230241_06351905_006_02.h5   \n",
       "2     ATL03_20230502223152_06501904_006_02.h5   \n",
       "3     ATL03_20230502223701_06501905_006_02.h5   \n",
       "4     ATL03_20230503092628_06571903_006_02.h5   \n",
       "...                                       ...   \n",
       "2063  ATL03_20230921165327_00412105_006_02.h5   \n",
       "2064  ATL03_20230925040010_00942103_006_02.h5   \n",
       "2065  ATL03_20230925164503_01022105_006_02.h5   \n",
       "2066  ATL03_20230929035148_01552103_006_02.h5   \n",
       "2067  ATL03_20230929163640_01632105_006_02.h5   \n",
       "\n",
       "                                      geojson        description  \\\n",
       "0     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "1     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "2     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "3     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "4     geojsons/simplified_GRE_2000_NE.geojson  GrIS_2023_2000_NE   \n",
       "...                                       ...                ...   \n",
       "2063  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "2064  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "2065  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "2066  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "2067  geojsons/simplified_GRE_2000_CW.geojson  GrIS_2023_2000_CW   \n",
       "\n",
       "                      geojson_clip      size_mb  \\\n",
       "0     geojsons/GRE_2000_NE.geojson  2336.841153   \n",
       "1     geojsons/GRE_2000_NE.geojson  1538.320868   \n",
       "2     geojsons/GRE_2000_NE.geojson  1913.935168   \n",
       "3     geojsons/GRE_2000_NE.geojson  1979.593719   \n",
       "4     geojsons/GRE_2000_NE.geojson  7311.369440   \n",
       "...                            ...          ...   \n",
       "2063  geojsons/GRE_2000_CW.geojson  3272.413673   \n",
       "2064  geojsons/GRE_2000_CW.geojson   501.831805   \n",
       "2065  geojsons/GRE_2000_CW.geojson  2889.815962   \n",
       "2066  geojsons/GRE_2000_CW.geojson   833.089432   \n",
       "2067  geojsons/GRE_2000_CW.geojson  2530.250005   \n",
       "\n",
       "                      granule_norelease  release  version  ttttccnn  \\\n",
       "0     ATL03_20230501225732_06351904_006        2        6   6351904   \n",
       "1     ATL03_20230501230241_06351905_006        2        6   6351905   \n",
       "2     ATL03_20230502223152_06501904_006        2        6   6501904   \n",
       "3     ATL03_20230502223701_06501905_006        2        6   6501905   \n",
       "4     ATL03_20230503092628_06571903_006        2        6   6571903   \n",
       "...                                 ...      ...      ...       ...   \n",
       "2063  ATL03_20230921165327_00412105_006        2        6    412105   \n",
       "2064  ATL03_20230925040010_00942103_006        2        6    942103   \n",
       "2065  ATL03_20230925164503_01022105_006        2        6   1022105   \n",
       "2066  ATL03_20230929035148_01552103_006        2        6   1552103   \n",
       "2067  ATL03_20230929163640_01632105_006        2        6   1632105   \n",
       "\n",
       "                        granule_region_id  select  \n",
       "0     6351904geojsons/GRE_2000_NE.geojson   False  \n",
       "1     6351905geojsons/GRE_2000_NE.geojson   False  \n",
       "2     6501904geojsons/GRE_2000_NE.geojson   False  \n",
       "3     6501905geojsons/GRE_2000_NE.geojson   False  \n",
       "4     6571903geojsons/GRE_2000_NE.geojson   False  \n",
       "...                                   ...     ...  \n",
       "2063   412105geojsons/GRE_2000_CW.geojson    True  \n",
       "2064   942103geojsons/GRE_2000_CW.geojson    True  \n",
       "2065  1022105geojsons/GRE_2000_CW.geojson    True  \n",
       "2066  1552103geojsons/GRE_2000_CW.geojson    True  \n",
       "2067  1632105geojsons/GRE_2000_CW.geojson    True  \n",
       "\n",
       "[2068 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_run_already = list(df_already_run.granule_region_id)\n",
    "df_new['select'] = df_new.apply(lambda x: x.granule_region_id not in ids_run_already, axis=1)\n",
    "print(np.sum(df_new.select))\n",
    "df_already_run\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "890e71a3-02c4-4a25-a095-a63c4cd26c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granule</th>\n",
       "      <th>geojson</th>\n",
       "      <th>description</th>\n",
       "      <th>geojson_clip</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>granule_norelease</th>\n",
       "      <th>release</th>\n",
       "      <th>version</th>\n",
       "      <th>ttttccnn</th>\n",
       "      <th>granule_region_id</th>\n",
       "      <th>select</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37830</th>\n",
       "      <td>ATL03_20181031235247_05090112_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_West_F-G.geojson</td>\n",
       "      <td>AIS_2018_1000_West_F-G</td>\n",
       "      <td>geojsons/ANT_1000_West_F-G.geojson</td>\n",
       "      <td>2392.604625</td>\n",
       "      <td>ATL03_20181031235247_05090112_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5090112</td>\n",
       "      <td>5090112geojsons/ANT_1000_West_F-G.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37439</th>\n",
       "      <td>ATL03_20181101024758_05110110_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_East_K-A.geojson</td>\n",
       "      <td>AIS_2018_1000_East_K-A</td>\n",
       "      <td>geojsons/ANT_1000_East_K-A.geojson</td>\n",
       "      <td>852.422195</td>\n",
       "      <td>ATL03_20181101024758_05110110_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5110110</td>\n",
       "      <td>5110110geojsons/ANT_1000_East_K-A.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35939</th>\n",
       "      <td>ATL03_20181101025539_05110111_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>AIS_2018_1000_West_Ep-F</td>\n",
       "      <td>geojsons/ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>2514.029597</td>\n",
       "      <td>ATL03_20181101025539_05110111_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5110111</td>\n",
       "      <td>5110111geojsons/ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35940</th>\n",
       "      <td>ATL03_20181101030122_05110112_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>AIS_2018_1000_West_Ep-F</td>\n",
       "      <td>geojsons/ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>1739.434034</td>\n",
       "      <td>ATL03_20181101030122_05110112_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5110112</td>\n",
       "      <td>5110112geojsons/ANT_1000_West_Ep-F.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34989</th>\n",
       "      <td>ATL03_20181101042215_05120110_006_02.h5</td>\n",
       "      <td>geojsons/simplified_ANT_1000_East_Jpp-K.geojson</td>\n",
       "      <td>AIS_2018_1000_East_Jpp-K</td>\n",
       "      <td>geojsons/ANT_1000_East_Jpp-K.geojson</td>\n",
       "      <td>568.969159</td>\n",
       "      <td>ATL03_20181101042215_05120110_006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5120110</td>\n",
       "      <td>5120110geojsons/ANT_1000_East_Jpp-K.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>ATL03_20230621213434_00262004_006_01.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NO.geojson</td>\n",
       "      <td>GrIS_2023_2000_NO</td>\n",
       "      <td>geojsons/GRE_2000_NO.geojson</td>\n",
       "      <td>3110.911763</td>\n",
       "      <td>ATL03_20230621213434_00262004_006</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>262004</td>\n",
       "      <td>262004geojsons/GRE_2000_NO.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>ATL03_20230621213943_00262005_006_01.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NW.geojson</td>\n",
       "      <td>GrIS_2023_2000_NW</td>\n",
       "      <td>geojsons/GRE_2000_NW.geojson</td>\n",
       "      <td>4143.117353</td>\n",
       "      <td>ATL03_20230621213943_00262005_006</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>262005</td>\n",
       "      <td>262005geojsons/GRE_2000_NW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>ATL03_20230621213943_00262005_006_01.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_CW.geojson</td>\n",
       "      <td>GrIS_2023_2000_CW</td>\n",
       "      <td>geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>4143.117353</td>\n",
       "      <td>ATL03_20230621213943_00262005_006</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>262005</td>\n",
       "      <td>262005geojsons/GRE_2000_CW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>ATL03_20230621231400_00272005_006_01.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NW.geojson</td>\n",
       "      <td>GrIS_2023_2000_NW</td>\n",
       "      <td>geojsons/GRE_2000_NW.geojson</td>\n",
       "      <td>4928.093561</td>\n",
       "      <td>ATL03_20230621231400_00272005_006</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>272005</td>\n",
       "      <td>272005geojsons/GRE_2000_NW.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>ATL03_20230621231400_00272005_006_01.h5</td>\n",
       "      <td>geojsons/simplified_GRE_2000_NO.geojson</td>\n",
       "      <td>GrIS_2023_2000_NO</td>\n",
       "      <td>geojsons/GRE_2000_NO.geojson</td>\n",
       "      <td>4928.093561</td>\n",
       "      <td>ATL03_20230621231400_00272005_006</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>272005</td>\n",
       "      <td>272005geojsons/GRE_2000_NO.geojson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51814 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       granule  \\\n",
       "37830  ATL03_20181031235247_05090112_006_02.h5   \n",
       "37439  ATL03_20181101024758_05110110_006_02.h5   \n",
       "35939  ATL03_20181101025539_05110111_006_02.h5   \n",
       "35940  ATL03_20181101030122_05110112_006_02.h5   \n",
       "34989  ATL03_20181101042215_05120110_006_02.h5   \n",
       "...                                        ...   \n",
       "5239   ATL03_20230621213434_00262004_006_01.h5   \n",
       "6683   ATL03_20230621213943_00262005_006_01.h5   \n",
       "6999   ATL03_20230621213943_00262005_006_01.h5   \n",
       "6684   ATL03_20230621231400_00272005_006_01.h5   \n",
       "5240   ATL03_20230621231400_00272005_006_01.h5   \n",
       "\n",
       "                                               geojson  \\\n",
       "37830    geojsons/simplified_ANT_1000_West_F-G.geojson   \n",
       "37439    geojsons/simplified_ANT_1000_East_K-A.geojson   \n",
       "35939   geojsons/simplified_ANT_1000_West_Ep-F.geojson   \n",
       "35940   geojsons/simplified_ANT_1000_West_Ep-F.geojson   \n",
       "34989  geojsons/simplified_ANT_1000_East_Jpp-K.geojson   \n",
       "...                                                ...   \n",
       "5239           geojsons/simplified_GRE_2000_NO.geojson   \n",
       "6683           geojsons/simplified_GRE_2000_NW.geojson   \n",
       "6999           geojsons/simplified_GRE_2000_CW.geojson   \n",
       "6684           geojsons/simplified_GRE_2000_NW.geojson   \n",
       "5240           geojsons/simplified_GRE_2000_NO.geojson   \n",
       "\n",
       "                    description                          geojson_clip  \\\n",
       "37830    AIS_2018_1000_West_F-G    geojsons/ANT_1000_West_F-G.geojson   \n",
       "37439    AIS_2018_1000_East_K-A    geojsons/ANT_1000_East_K-A.geojson   \n",
       "35939   AIS_2018_1000_West_Ep-F   geojsons/ANT_1000_West_Ep-F.geojson   \n",
       "35940   AIS_2018_1000_West_Ep-F   geojsons/ANT_1000_West_Ep-F.geojson   \n",
       "34989  AIS_2018_1000_East_Jpp-K  geojsons/ANT_1000_East_Jpp-K.geojson   \n",
       "...                         ...                                   ...   \n",
       "5239          GrIS_2023_2000_NO          geojsons/GRE_2000_NO.geojson   \n",
       "6683          GrIS_2023_2000_NW          geojsons/GRE_2000_NW.geojson   \n",
       "6999          GrIS_2023_2000_CW          geojsons/GRE_2000_CW.geojson   \n",
       "6684          GrIS_2023_2000_NW          geojsons/GRE_2000_NW.geojson   \n",
       "5240          GrIS_2023_2000_NO          geojsons/GRE_2000_NO.geojson   \n",
       "\n",
       "           size_mb                  granule_norelease  release  version  \\\n",
       "37830  2392.604625  ATL03_20181031235247_05090112_006        2        6   \n",
       "37439   852.422195  ATL03_20181101024758_05110110_006        2        6   \n",
       "35939  2514.029597  ATL03_20181101025539_05110111_006        2        6   \n",
       "35940  1739.434034  ATL03_20181101030122_05110112_006        2        6   \n",
       "34989   568.969159  ATL03_20181101042215_05120110_006        2        6   \n",
       "...            ...                                ...      ...      ...   \n",
       "5239   3110.911763  ATL03_20230621213434_00262004_006        1        6   \n",
       "6683   4143.117353  ATL03_20230621213943_00262005_006        1        6   \n",
       "6999   4143.117353  ATL03_20230621213943_00262005_006        1        6   \n",
       "6684   4928.093561  ATL03_20230621231400_00272005_006        1        6   \n",
       "5240   4928.093561  ATL03_20230621231400_00272005_006        1        6   \n",
       "\n",
       "       ttttccnn                            granule_region_id  select  \n",
       "37830   5090112    5090112geojsons/ANT_1000_West_F-G.geojson    True  \n",
       "37439   5110110    5110110geojsons/ANT_1000_East_K-A.geojson    True  \n",
       "35939   5110111   5110111geojsons/ANT_1000_West_Ep-F.geojson    True  \n",
       "35940   5110112   5110112geojsons/ANT_1000_West_Ep-F.geojson    True  \n",
       "34989   5120110  5120110geojsons/ANT_1000_East_Jpp-K.geojson    True  \n",
       "...         ...                                          ...     ...  \n",
       "5239     262004           262004geojsons/GRE_2000_NO.geojson    True  \n",
       "6683     262005           262005geojsons/GRE_2000_NW.geojson    True  \n",
       "6999     262005           262005geojsons/GRE_2000_CW.geojson    True  \n",
       "6684     272005           272005geojsons/GRE_2000_NW.geojson    True  \n",
       "5240     272005           272005geojsons/GRE_2000_NO.geojson    True  \n",
       "\n",
       "[51814 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_already_run.sort_values(by='granule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25c382-e778-4e3a-bfe5-1e58acf65a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_already_run.apply(lambda x: x.granule[6:14], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284642d-4c54-4988-b5db-d7227fff8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnewall = df_all.copy()\n",
    "dfnewall['granule_norelease'] = dfnewall.apply(lambda x: x.granule[:x.granule.rfind('_')], axis=1)\n",
    "dfnewall['release'] = dfnewall.apply(lambda x: int(x.granule.split('_')[-1][:2]), axis=1)\n",
    "print(len(np.unique(dfnewall.granule_norelease)), len(np.unique(dfnewall.granule)), len(dfnewall))\n",
    "\n",
    "print(dfnewall.groupby(by='release')['granule'].count())\n",
    "dfnewall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260554ad-c514-4661-a56e-0b81d2fbe4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dae1f-7917-4b5c-af57-d5d70cc6219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df.select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10414a0f-a67e-4f19-bc23-9335fc32d1c5",
   "metadata": {},
   "source": [
    "# Greenland 2019 - June 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0fa54-ab3d-4b62-ba0d-fcf9e4d87e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "filename_out = 'granule_lists/GRE_2000_May2019_Jun2023.csv'\n",
    "\n",
    "startyear = 2019\n",
    "endyear = 2023\n",
    "startday = '05-15'\n",
    "endday = '09-15'\n",
    "icesheet = 'GrIS'\n",
    "\n",
    "searchfor = 'simplified_GRE_2000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "print('____________________________________________________________________________')\n",
    "print('GREENLAND')\n",
    "print('____________________________________________________________________________')\n",
    "\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear+1):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "df_all.to_csv(filename_out.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_all.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_all.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_all))\n",
    "maxrow = df_all.loc[np.argmax(df_all.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_all.size_mb)/1e6))\n",
    "\n",
    "df_all_nosize = df_all.drop(columns='size_mb').copy()\n",
    "df_all_nosize.to_csv(filename_out, header=False, index=False)\n",
    "df_all_nosize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c43d20-ed7d-447a-80be-3bd4cffb418d",
   "metadata": {},
   "source": [
    "# Antarctica 2018/19 - 2020/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592ac93-2a18-4e98-9b2c-a24debb53089",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "filename_out = 'granule_lists/ANT_1000_Dec2018_Mar2021.csv'\n",
    "\n",
    "startyear = 2018\n",
    "endyear = 2021\n",
    "startday = '12-01'\n",
    "endday = '03-01'\n",
    "icesheet = 'AIS'\n",
    "\n",
    "searchfor = 'simplified_ANT_1000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "print('____________________________________________________________________________')\n",
    "print('ANTARCTICA 2018/19 - 2020/21')\n",
    "print('____________________________________________________________________________')\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr+1, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "df_all.to_csv(filename_out.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_all.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_all.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_all))\n",
    "maxrow = df_all.loc[np.argmax(df_all.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_all.size_mb)/1e6))\n",
    "\n",
    "df_all_nosize = df_all.drop(columns='size_mb').copy()\n",
    "df_all_nosize.to_csv(filename_out, header=False, index=False)\n",
    "df_all_nosize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b96c84-9b5e-45a4-9119-82790753fa8f",
   "metadata": {},
   "source": [
    "# Antarctica 2021/22 - 2022/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbe018-f535-4564-8f45-252812ddfabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "filename_out = 'granule_lists/ANT_1000_Dec2021_Mar2023.csv'\n",
    "\n",
    "startyear = 2021\n",
    "endyear = 2023\n",
    "startday = '12-01'\n",
    "endday = '03-01'\n",
    "icesheet = 'AIS'\n",
    "\n",
    "searchfor = 'simplified_ANT_1000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "print('____________________________________________________________________________')\n",
    "print('ANTARCTICA 2021/22 - 2022/23')\n",
    "print('____________________________________________________________________________')\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr+1, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "df_all.to_csv(filename_out.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_all.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_all.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_all))\n",
    "maxrow = df_all.loc[np.argmax(df_all.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_all.size_mb)/1e6))\n",
    "\n",
    "df_all_nosize = df_all.drop(columns='size_mb').copy()\n",
    "df_all_nosize.to_csv(filename_out, header=False, index=False)\n",
    "df_all_nosize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c5ae7-1b09-472d-9739-c452fe17f95d",
   "metadata": {},
   "source": [
    "# greenland extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3583c-c5f8-492e-be2a-37dc7dbd8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out = 'granule_lists/GRE_2000_extraMaySep.csv'\n",
    "dflist = []\n",
    "\n",
    "startyear = 2019\n",
    "endyear = 2023\n",
    "icesheet = 'GrIS'\n",
    "searchfor = 'simplified_GRE_2000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "print('____________________________________________________________________________')\n",
    "print('GREENLAND EXTRA')\n",
    "print('____________________________________________________________________________')\n",
    "\n",
    "startday = '05-01'\n",
    "endday = '05-14'\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear+1):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "startday = '09-16'\n",
    "endday = '09-30'\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear+1):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "df_all.to_csv(filename_out.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_all.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_all.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_all))\n",
    "maxrow = df_all.loc[np.argmax(df_all.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_all.size_mb)/1e6))\n",
    "\n",
    "df_all_nosize = df_all.drop(columns='size_mb').copy()\n",
    "df_all_nosize.to_csv(filename_out, header=False, index=False)\n",
    "df_all_nosize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae89200-6c77-4e58-8042-3be285b0bdb3",
   "metadata": {},
   "source": [
    "# antarctica extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb047bc-3341-45be-9591-7a1c77047512",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "filename_out = 'granule_lists/ANT_1000_extraNovMar.csv'\n",
    "\n",
    "startyear = 2018\n",
    "endyear = 2023\n",
    "icesheet = 'AIS'\n",
    "searchfor = 'simplified_ANT_1000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "print('____________________________________________________________________________')\n",
    "print('ANTARCTICA EXTRA')\n",
    "print('____________________________________________________________________________')\n",
    "\n",
    "startday = '11-01'\n",
    "endday = '11-30'\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "startday = '03-01'\n",
    "endday = '03-31'\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear):\n",
    "        start_date = '%s-%s' % (yr+1, startday)\n",
    "        end_date = '%s-%s' % (yr+1, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "df_all.to_csv(filename_out.replace('.csv', '_size.csv'), header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_all.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_all.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_all))\n",
    "maxrow = df_all.loc[np.argmax(df_all.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_all.size_mb)/1e6))\n",
    "\n",
    "df_all_nosize = df_all.drop(columns='size_mb').copy()\n",
    "df_all_nosize.to_csv(filename_out, header=False, index=False)\n",
    "df_all_nosize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f664f895-b6f9-474e-b6e9-2762dd808ed2",
   "metadata": {},
   "source": [
    "# combine both ANT and GRE extra job inputs for shoulder season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce181e-09c2-45ff-8b5f-aaac76a99ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('granule_lists/GRE_2000_extraMaySep.csv',header=None)\n",
    "df2 = pd.read_csv('granule_lists/ANT_1000_extraNovMar.csv',header=None)\n",
    "dfb = pd.concat((df1,df2))\n",
    "dfb.to_csv('granule_lists/extra_shoulderseason_GRE_2000_ANT_1000.csv', header=False, index=False)\n",
    "\n",
    "nms = ['granule', 'geojson', 'description', 'geojson_clip', 'size_mb']\n",
    "df1 = pd.read_csv('granule_lists/GRE_2000_extraMaySep_size.csv',header=None,names=nms)\n",
    "df2 = pd.read_csv('granule_lists/ANT_1000_extraNovMar_size.csv',header=None,names=nms)\n",
    "dfb = pd.concat((df1,df2)).reset_index(drop=True)\n",
    "dfb.to_csv('granule_lists/extra_shoulderseason_GRE_2000_ANT_1000_size.csv', header=False, index=False)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(dfb.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(dfb.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(dfb))\n",
    "maxrow = dfb.loc[np.argmax(dfb.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(dfb.size_mb)/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e27a66-c378-4c93-b86b-19d485179517",
   "metadata": {},
   "outputs": [],
   "source": [
    "17305+1762"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c3ec97-11ba-4927-a0c5-9a61da828967",
   "metadata": {},
   "source": [
    "# stats for all combined inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafec533-8af3-4003-a25b-5019119e6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_list = [\n",
    "    'granule_lists/GRE_2000_May2019_Jun2023.csv',\n",
    "    'granule_lists/ANT_1000_Dec2018_Mar2021.csv',\n",
    "    'granule_lists/ANT_1000_Dec2021_Mar2023.csv',\n",
    "    'granule_lists/extra_shoulderseason_GRE_2000_ANT_1000.csv']\n",
    "nms = ['granule', 'geojson', 'description', 'geojson_clip', 'size_mb']\n",
    "dfs_all_input = []\n",
    "for grlist in in_list:\n",
    "    dfs_all_input.append(pd.read_csv(grlist.replace('.csv', '_size.csv'), header=None, names=nms))\n",
    "df_all_inputs = pd.concat(dfs_all_input).reset_index(drop=True)\n",
    "\n",
    "print('Number of ganules over Greenland:', np.sum(df_all_inputs.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_all_inputs.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_all_inputs))\n",
    "maxrow = df_all_inputs.loc[np.argmax(df_all_inputs.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_all_inputs.size_mb)/1e6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819890e-8166-497f-bc81-8fd7d335b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_all_inputs.size_mb > 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382409f0-8a57-4c7e-8489-f4ce229ac506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280922a-30ec-4cec-b430-95e19fca4335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d19743-6106-491d-9550-56be5ff5969e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c5e46-9edc-45e2-9ad4-8072bed2eb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f8df2-08ea-4401-96f6-2c786ad4065c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee4a35-75c0-496f-b1fc-edbbb35e7b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c0240-ba0c-49fa-ba0c-a8831d24dee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40101fe0-a8b7-46f5-af7c-e622ea15528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee09b33-3a47-43ae-88c0-ddc4cb75309d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e0480-8f48-4fe1-b633-e2a7738b9d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6f16b-4f3d-4998-8ad8-bf85d7775d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_in = 'granule_lists/GRE_2500_ANT_1500_Oct2018_Mar2023.csv'\n",
    "fn_in = 'granule_lists/GRE_2000_ANT_1000_Oct2018_Mar2023.csv'\n",
    "fn_in = 'granule_lists/GRE_2000_ANT_1000_Oct2018_Jun2023.csv'\n",
    "n_granules = 1000\n",
    "\n",
    "df = pd.read_csv(fn_in, header=None)\n",
    "if n_granules == 1:\n",
    "    df_small = df[df.apply(lambda x: 'ATL03_20220714010847' in x.loc[0], axis=1)]\n",
    "else:\n",
    "    idxs = np.random.choice(np.arange(0,len(df)), size=n_granules, replace=False)\n",
    "    df_small = df.loc[idxs, :]\n",
    "    \n",
    "fn_out = fn_in.replace('.csv', '-%i.csv' % n_granules)\n",
    "print(fn_out)\n",
    "\n",
    "df_small.to_csv(fn_out, header=False, index=False)\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad108-a9de-47be-8a24-769484935ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the longest polygon to check if query code works with it\n",
    "gjsn_dir = 'geojsons'\n",
    "searchfor = 'simplified_GRE_2500'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "searchfor = 'simplified_ANT_1500'\n",
    "gjsn_list += [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "for geojson_filepath in gjsn_list:\n",
    "    gdf = gpd.read_file(geojson_filepath)\n",
    "    poly = orient(gdf.loc[0].geometry,sign=1.0)\n",
    "    polygon = ','.join([str(c) for xy in zip(*poly.exterior.coords.xy) for c in xy])\n",
    "    print('%4i'%len(polygon), geojson_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935d0c9-0ffd-4b37-9357-6f30332196e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 detect_lakes.py --granule ATL03_20200302160852_10220610_006_01.h5 --polygon geojsons/simplified_ANT_1500_East_Dp-E.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be39da8-0b39-43bd-8655-9788a2dbaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = np.linspace(2,8)\n",
    "xp = np.array([])\n",
    "fp = np.sin(xp)\n",
    "x = np.linspace(0,10)\n",
    "len(xp)\n",
    "#np.interp(x, xp, fp, left=np.nan, right=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3e54d-21af-4b5d-9648-0664113be718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of dataframes\n",
    "dflist = []\n",
    "\n",
    "startyear = 2019\n",
    "endyear = 2022\n",
    "startday = '05-01'\n",
    "endday = '09-30'\n",
    "icesheet = 'GrIS'\n",
    "\n",
    "searchfor = 'simplified_GRE_2500_CW'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "for gjsn in gjsn_list:\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "\n",
    "    # gdf = gpd.read_file(gjsn)\n",
    "    # print(gdf.geometry.loc[0].geom_type, geojson)\n",
    "    \n",
    "    for yr in np.arange(startyear, endyear+1):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(pd.read_csv(outname,header=None))\n",
    "\n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 3] = df_all.apply(lambda x: x.loc[1].replace('simplified_', ''), axis=1)\n",
    "df_all.loc[:, 2] = df_all.apply(lambda x: x.loc[2].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.to_csv('granule_lists/GRE_2500_CW_2019-22_.csv', header=False, index=False)\n",
    "df_all_nosize = df_all.drop(columns='size_mb').copy()\n",
    "df_all_nosize.to_csv('granule_lists/GRE_2000_ANT_1000_Oct2018_Jun2023.csv', header=False, index=False)\n",
    "df_all_nosize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce22efd-94b3-490a-90b5-a6141e4575bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "polygon = 'geojsons/simplified_GRE_2500_CW.geojson'\n",
    "poly_nonsimplified = polygon.replace('simplified_', '')\n",
    "poly_nonsimplified\n",
    "clip_shape = gpd.read_file(poly_nonsimplified)\n",
    "clip_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065350e-58b8-4ff3-8f74-537d3e072051",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('geojsons/simplified_GRE_2500_NO.geojson')\n",
    "poly = orient(gdf.loc[0].geometry,sign=1.0)\n",
    "    \n",
    "#Format dictionary to polygon coordinate pairs for CMR polygon filtering\n",
    "polygon = ','.join([str(c) for xy in zip(*poly.exterior.coords.xy) for c in xy])\n",
    "polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482dfd0f-1e72-4d5e-86ca-c1158ece63e4",
   "metadata": {},
   "source": [
    "# Greenland and Antarctica, all regions, Oct 2018 - March 2022\n",
    "\n",
    "For GRE2500/ANT1500:\n",
    "- Number of ganules over Greenland: 9325\n",
    "- Number of ganules over Antarctica: 43790\n",
    "- Total number of granules: 53115\n",
    "- Largest granule: 12.2 GB, ATL03_20220511191525_07591505_006_01.h5, geojsons/simplified_GRE_2500_NW.geojson\n",
    "- Total size: 141.03 TB 3 TB\n",
    "\n",
    "For GRE2000/ANT1000:\n",
    "- Number of ganules over Greenland: 8068\n",
    "- Number of ganules over Antarctica: 39947\n",
    "- Total number of granules: 48015\n",
    "- Largest granule: 12.2 GB, ATL03_20220511191525_07591505_006_01.h5, geojsons/simplified_GRE_2000_NO.geojson\n",
    "- Total size: 128.30 TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8792df27-a652-48e7-ab47-0aca2ba2cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of dataframes\n",
    "dflist = []\n",
    "\n",
    "startyear = 2019\n",
    "endyear = 2023\n",
    "startday = '05-01'\n",
    "endday = '09-30'\n",
    "icesheet = 'GrIS'\n",
    "\n",
    "searchfor = 'simplified_GRE_2000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "print('____________________________________________________________________________')\n",
    "print('GREENLAND')\n",
    "print('____________________________________________________________________________')\n",
    "\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear+1):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "\n",
    "startyear = 2018\n",
    "endyear = 2023\n",
    "startday = '11-01'\n",
    "endday = '03-15'\n",
    "icesheet = 'AIS'\n",
    "\n",
    "searchfor = 'simplified_ANT_1000'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "print('____________________________________________________________________________')\n",
    "print('ANTARCTICA')\n",
    "print('____________________________________________________________________________')\n",
    "for i, gjsn in enumerate(gjsn_list):\n",
    "    geojson = gjsn[gjsn.rfind('/')+1:]\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(geojson, '(', i+1, '/', len(gjsn_list), ')')\n",
    "    for yr in np.arange(startyear, endyear):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr+1, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        df = make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(df)\n",
    "    \n",
    "df_all = pd.concat(dflist)\n",
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "df_all.to_csv('granule_lists/GRE_2000_ANT_1000_Oct2018_Jun2023_size.csv', header=False, index=False)\n",
    "print('Number of ganules over Greenland:', np.sum(df_all.apply(lambda x: 'GrIS' in x.loc['description'], axis=1)))\n",
    "print('Number of ganules over Antarctica:', np.sum(df_all.apply(lambda x: 'AIS' in x.loc['description'], axis=1)))\n",
    "print('Total number of granules:', len(df_all))\n",
    "maxrow = df_all.loc[np.argmax(df_all.size_mb),:]\n",
    "print('Largest granule: %.1f GB, %s, %s' % (maxrow.size_mb/1000, maxrow.granule, maxrow.geojson))\n",
    "print('Total size: %.2f TB' % (np.sum(df_all.size_mb)/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fe728-6b74-4735-a6bc-40735c2ea8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_nosize = df_all.drop(columns='size_mb').copy()\n",
    "df_all_nosize.to_csv('granule_lists/GRE_2000_ANT_1000_Oct2018_Jun2023.csv', header=False, index=False)\n",
    "df_all_nosize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057643d2-e1fa-4557-9cad-4d98970e506a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ce407-0855-46c1-af5d-72834e971e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e7933-01b4-4066-99cc-c5249b97450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[:, 'description'] = df_all.apply(lambda x: x.loc['description'].replace('simplified_','').replace('GRE_','').replace('ANT_',''), axis=1)\n",
    "df_all.to_csv('granule_lists/GRE_2500_ANT_1500_Oct2018_Mar2023_size.csv', header=False, index=False)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c68b1d-09f5-498d-9817-cbdc67fd1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('granule_lists/GRE_2500_ANT_1500_Oct2018_Mar2023_size.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac518a-0058-4afa-b4dd-1e878afe600f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78668653-72f3-4d07-a992-63dfcbdd87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da726668-8da2-4128-9fd8-a1332988936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(df_all.size_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5da94-d28f-43b0-8ec3-9a29468acd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[np.argmax(df_all.size_mb),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045019b-963f-4514-9428-8491f8bb466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e86538-730e-4ec1-a380-e89ee91df910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bb71e-c570-4f1b-b602-7dca389a7c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8f421-58ea-4621-9c31-3f3bf6f5e681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c75dc-48a1-44b5-9d8c-7a6d01985a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson = 'jakobshavn_test.geojson'\n",
    "icesheet = 'GrIS'\n",
    "startyear = 2022\n",
    "endyear = 2022\n",
    "startday = '07-14'\n",
    "endday = '07-14'\n",
    "start_date = '%s-%s' % (startyear, startday)\n",
    "end_date = '%s-%s' % (endyear, endday)\n",
    "\n",
    "\n",
    "meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "outname = 'zzz_test006.csv'\n",
    "\n",
    "make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "pd.read_csv(outname,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e9c0a-4bb2-497d-bead-ad5836db2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that it worked by reading the file into a DataFrame and displaying it\n",
    "import pandas as pd\n",
    "pd.read_csv(outname,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9d6f8-cf58-4651-84c3-201c9bfe3be8",
   "metadata": {},
   "source": [
    "# Jakobshavn + Amery + George VI all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990e69b-515b-44a7-95ec-2432cfa3ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters and make the list\n",
    "geojson = 'jakobshavn_test.geojson'\n",
    "icesheet = 'GrIS'\n",
    "startyear = 2019\n",
    "endyear = 2022\n",
    "startday = '05-15'\n",
    "endday = '09-15'\n",
    "\n",
    "\n",
    "meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "\n",
    "make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4717cb-96b2-4c94-abb0-86be43fd8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters and make the list\n",
    "geojson = 'west_greenland.geojson'\n",
    "icesheet = 'GrIS'\n",
    "startyear = 2019\n",
    "endyear = 2022\n",
    "startday = '05-15'\n",
    "endday = '09-15'\n",
    "\n",
    "dflist = []\n",
    "for yr in np.arange(startyear, endyear+1):\n",
    "    start_date = '%s-%s' % (yr, startday)\n",
    "    end_date = '%s-%s' % (yr, endday)\n",
    "    \n",
    "    meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "    outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "\n",
    "    make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "    dflist.append(pd.read_csv(outname,header=None))\n",
    "    \n",
    "geojson1 = 'george_vi.geojson'\n",
    "geojson2 = 'amery.geojson'\n",
    "icesheet = 'AIS'\n",
    "startyear = 2018\n",
    "endyear = 2021\n",
    "startday = '11-15'\n",
    "endday = '03-15'\n",
    "\n",
    "for yr in np.arange(startyear, endyear+1):\n",
    "    start_date = '%s-%s' % (yr, startday)\n",
    "    end_date = '%s-%s' % (yr+1, endday)\n",
    "    \n",
    "    meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "    outname1 = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson1.replace('.geojson','') + '.csv'\n",
    "    outname2 = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson2.replace('.geojson','') + '.csv'\n",
    "    \n",
    "    make_granule_list(geojson1, start_date, end_date, icesheet, meltseason, outname1)\n",
    "    make_granule_list(geojson2, start_date, end_date, icesheet, meltseason, outname2)\n",
    "    \n",
    "    dflist.append(pd.read_csv(outname1,header=None))\n",
    "    dflist.append(pd.read_csv(outname2,header=None))\n",
    "    \n",
    "df_all = pd.concat(dflist)  \n",
    "df_all.to_csv('granule_lists/wais-areas.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441f66d-202d-47d6-acfd-570b2ec67d65",
   "metadata": {},
   "source": [
    "# granule list from failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f2e92-cf2f-4bdf-917d-f6eb3a5f753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('failed_jobs/jobs_failed.csv', header=None)\n",
    "def get_geo(x): \n",
    "    for area in ['amery', 'west_greenland', 'george_vi']:\n",
    "        if area in x: \n",
    "            return 'geojsons/'+area+'.geojson', x[(x.find('job_')+4) : (x.find(area)+len(area))]\n",
    "df['granule'] = df[0].map(lambda x : x[x.find('ATL03') : (x.find('.h5')+3)])\n",
    "df['geo'], df['desc'] = list(zip(*df[0].map(get_geo)))\n",
    "df.drop([0],inplace=True,axis=1)\n",
    "df.to_csv('granule_lists/wais-areas_failed1.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9764710-5db8-454f-8bc5-79d34cd30e39",
   "metadata": {},
   "source": [
    "# granule list for all of WAIS melt regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da34078-d587-470b-bc5e-4884a190e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "icesheet = 'AIS'\n",
    "startyear = 2018\n",
    "endyear = 2021\n",
    "startday = '11-01'\n",
    "endday = '03-15'\n",
    "\n",
    "searchfor = 'waismeltregions'\n",
    "gjsn_dir = 'geojsons'\n",
    "gjsn_list = [gjsn_dir+'/'+f for f in os.listdir(gjsn_dir) \\\n",
    "            if os.path.isfile(os.path.join(gjsn_dir, f)) & (searchfor in f)]\n",
    "\n",
    "dflist = []\n",
    "for gjsn in gjsn_list:\n",
    "    geojson = gjsn[gjsn.find('/')+1:]\n",
    "    for yr in np.arange(startyear, endyear+1):\n",
    "        start_date = '%s-%s' % (yr, startday)\n",
    "        end_date = '%s-%s' % (yr+1, endday)\n",
    "        meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "        outname = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson.replace('.geojson','') + '.csv'\n",
    "        make_granule_list(geojson, start_date, end_date, icesheet, meltseason, outname)\n",
    "        dflist.append(pd.read_csv(outname,header=None))\n",
    "    \n",
    "df_all = pd.concat(dflist)\n",
    "df_all.to_csv('granule_lists/waismeltregions.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d6ad8-9368-4991-9689-3d2b70bda3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['granule'] = 'granule'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5220212-79d1-4f4b-90ee-48d862b44d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cbd496-d5c1-4bb4-b8ed-42f6851028c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c45d58-1c6a-4dae-9c98-58b3aba1d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters and make the list\n",
    "geojson1 = 'george_vi.geojson'\n",
    "geojson2 = 'amery.geojson'\n",
    "icesheet = 'AIS'\n",
    "startyear = 2018\n",
    "endyear = 2021\n",
    "startday = '11-15'\n",
    "endday = '03-15'\n",
    "\n",
    "dflist = []\n",
    "for yr in np.arange(startyear, endyear+1):\n",
    "    start_date = '%s-%s' % (yr, startday)\n",
    "    end_date = '%s-%s' % (yr+1, endday)\n",
    "    print(start_date, end_date)\n",
    "    \n",
    "    meltseason = start_date[:4] if start_date[:4]==end_date[:4] else start_date[:4] + '-' + end_date[2:4]\n",
    "    outname1 = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson1.replace('.geojson','') + '.csv'\n",
    "    outname2 = 'granule_lists/' + icesheet + '_' + meltseason + '_' + geojson2.replace('.geojson','') + '.csv'\n",
    "    \n",
    "    make_granule_list(geojson1, start_date, end_date, icesheet, meltseason, outname1)\n",
    "    make_granule_list(geojson2, start_date, end_date, icesheet, meltseason, outname2)\n",
    "    \n",
    "    dflist.append(pd.read_csv(outname1,header=None))\n",
    "    dflist.append(pd.read_csv(outname2,header=None))\n",
    "    \n",
    "df_all = pd.concat(dflist)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9cf51-478c-4063-a647-d208099f468a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icepyx-env",
   "language": "python",
   "name": "icepyx-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
